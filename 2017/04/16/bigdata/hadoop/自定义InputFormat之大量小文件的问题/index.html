<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>自定义InputFormat之大量小文件的问题 | Chen&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="默认情况下，TextInputFormat对任务的切片机制是按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个maptask，这样，如果有大量小文件，就会产生大量的maptask，处理效率极其低下">
<meta name="keywords" content="hadoop,mapreduce">
<meta property="og:type" content="article">
<meta property="og:title" content="自定义InputFormat之大量小文件的问题">
<meta property="og:url" content="http://yoursite.com/2017/04/16/bigdata/hadoop/自定义InputFormat之大量小文件的问题/index.html">
<meta property="og:site_name" content="Chen's Blog">
<meta property="og:description" content="默认情况下，TextInputFormat对任务的切片机制是按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个maptask，这样，如果有大量小文件，就会产生大量的maptask，处理效率极其低下">
<meta property="og:updated_time" content="2017-02-27T05:55:04.798Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="自定义InputFormat之大量小文件的问题">
<meta name="twitter:description" content="默认情况下，TextInputFormat对任务的切片机制是按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个maptask，这样，如果有大量小文件，就会产生大量的maptask，处理效率极其低下">
  
    <link rel="alternate" href="/atom.xml" title="Chen&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Chen&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一个技术渣的自说自话</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-bigdata/hadoop/自定义InputFormat之大量小文件的问题" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/04/16/bigdata/hadoop/自定义InputFormat之大量小文件的问题/" class="article-date">
  <time datetime="2017-04-16T04:47:25.055Z" itemprop="datePublished">2017-04-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      自定义InputFormat之大量小文件的问题
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>默认情况下，TextInputFormat对任务的切片机制是按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个maptask，这样，如果有大量小文件，就会产生大量的maptask，处理效率极其低下</p>
<a id="more"></a>
<h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>小文件的优化无非以下几种方式：<br>1、在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS<br>2、在业务处理之前，在HDFS上使用mapreduce程序对小文件进行合并<br>3、在mapreduce处理时，可采用combineInputFormat提高效率</p>
<h1 id="采用combineInputFormat"><a href="#采用combineInputFormat" class="headerlink" title="采用combineInputFormat"></a>采用combineInputFormat</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">/*如果不设置InputFormat，它默认用的是TextInputformat.class</div><div class="line">   * 只是将多个小文件放在一个切片中，即一个maptask中</div><div class="line">  */</div><div class="line">  job.setInputFormatClass(CombineTextInputFormat.class);</div><div class="line">  CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);</div><div class="line">  CombineTextInputFormat.setMinInputSplitSize(job, 2097152);</div></pre></td></tr></table></figure>
<h1 id="自定义InputFormat"><a href="#自定义InputFormat" class="headerlink" title="自定义InputFormat"></a>自定义InputFormat</h1><p>实现方式:<br>1.自定义一个InputFormat<br>2.改写RecordReader，实现一次读取一个完整文件封装为KV<br>3.在输出时使用SequenceFileOutPutFormat输出合并文件</p>
<p>代码如下：<br>自定义InputFromat</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">package cn.itcast.bigdata.combinefile;</div><div class="line"> </div><div class="line">import java.io.IOException;</div><div class="line"> </div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.BytesWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.mapreduce.InputSplit;</div><div class="line">import org.apache.hadoop.mapreduce.JobContext;</div><div class="line">import org.apache.hadoop.mapreduce.RecordReader;</div><div class="line">import org.apache.hadoop.mapreduce.TaskAttemptContext;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"> </div><div class="line">public class WholeFileInputFormat extends FileInputFormat&lt;NullWritable, BytesWritable&gt;&#123;</div><div class="line"> </div><div class="line">@Override</div><div class="line">protected boolean isSplitable(JobContext context, Path file) &#123;</div><div class="line">  return false;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">@Override</div><div class="line">public RecordReader&lt;NullWritable, BytesWritable&gt; createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException,InterruptedException &#123;</div><div class="line">  WholeFileRecordReader reader = new WholeFileRecordReader();</div><div class="line">  reader.initialize(split, context);</div><div class="line">  return reader;</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>自定义RecordReader</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div></pre></td><td class="code"><pre><div class="line">package cn.itcast.bigdata.combinefile;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line"></div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.FSDataInputStream;</div><div class="line">import org.apache.hadoop.fs.FileSystem;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.BytesWritable;</div><div class="line">import org.apache.hadoop.io.IOUtils;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.mapreduce.InputSplit;</div><div class="line">import org.apache.hadoop.mapreduce.RecordReader;</div><div class="line">import org.apache.hadoop.mapreduce.TaskAttemptContext;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileSplit;</div><div class="line"></div><div class="line">/**</div><div class="line"> * </div><div class="line"> * RecordReader的核心工作逻辑：</div><div class="line"> * 通过nextKeyValue()方法去读取数据构造将返回的key   value</div><div class="line"> * 通过getCurrentKey 和 getCurrentValue来返回上面构造好的key和value</div><div class="line"> */</div><div class="line">class WholeFileRecordReader extends RecordReader&lt;NullWritable, BytesWritable&gt; &#123;</div><div class="line">	private FileSplit fileSplit;</div><div class="line">	private Configuration conf;</div><div class="line">	private BytesWritable value = new BytesWritable();</div><div class="line">	private boolean processed = false;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public void initialize(InputSplit split, TaskAttemptContext context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		this.fileSplit = (FileSplit) split;</div><div class="line">		this.conf = context.getConfiguration();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public boolean nextKeyValue() throws IOException, InterruptedException &#123;</div><div class="line">		if (!processed) &#123;</div><div class="line">			byte[] contents = new byte[(int) fileSplit.getLength()];</div><div class="line">			Path file = fileSplit.getPath();</div><div class="line">			FileSystem fs = file.getFileSystem(conf);</div><div class="line">			FSDataInputStream in = null;</div><div class="line">			try &#123;</div><div class="line">				in = fs.open(file);</div><div class="line">				IOUtils.readFully(in, contents, 0, contents.length);</div><div class="line">				value.set(contents, 0, contents.length);</div><div class="line">			&#125; finally &#123;</div><div class="line">				IOUtils.closeStream(in);</div><div class="line">			&#125;</div><div class="line">			processed = true;//设置为true，那么将只会读取一次，也就是只是返回一个keyValue，一个文件读取完毕</div><div class="line">			</div><div class="line">			return true;</div><div class="line">		&#125;</div><div class="line">		return false;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	</div><div class="line">	</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	public NullWritable getCurrentKey() throws IOException,</div><div class="line">			InterruptedException &#123;</div><div class="line">		return NullWritable.get();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public BytesWritable getCurrentValue() throws IOException,</div><div class="line">			InterruptedException &#123;</div><div class="line">		return value;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	/**</div><div class="line">	 * 返回当前进度</div><div class="line">	 */</div><div class="line">	@Override</div><div class="line">	public float getProgress() throws IOException &#123;</div><div class="line">		//框架会调用该方法，返回读取的进度，因为只是读取一次（读完整个文件），所以是要么读完了，要么没有读完</div><div class="line">		return processed ? 1.0f : 0.0f;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public void close() throws IOException &#123;</div><div class="line">		// do nothing</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>定义mapreduce处理流程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div></pre></td><td class="code"><pre><div class="line">package cn.itcast.bigdata.combinefile;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line"></div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.conf.Configured;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.BytesWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.InputSplit;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileSplit;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;</div><div class="line">import org.apache.hadoop.util.GenericOptionsParser;</div><div class="line">import org.apache.hadoop.util.Tool;</div><div class="line">import org.apache.hadoop.util.ToolRunner;</div><div class="line"></div><div class="line">public class SmallFilesToSequenceFileConverter extends Configured implements Tool &#123;</div><div class="line">	static class SequenceFileMapper extends	Mapper&lt;NullWritable, BytesWritable, Text, BytesWritable&gt; &#123;</div><div class="line">		private Text filenameKey;</div><div class="line"></div><div class="line">		@Override</div><div class="line">		protected void setup(Context context) throws IOException, InterruptedException &#123;</div><div class="line">			InputSplit split = context.getInputSplit();</div><div class="line">			Path path = ((FileSplit) split).getPath();</div><div class="line">			//拿到文件的路径，作为key</div><div class="line">			filenameKey = new Text(path.toString());</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		@Override</div><div class="line">		protected void map(NullWritable key, BytesWritable value, Context context) throws IOException, InterruptedException &#123;</div><div class="line">			//以文件路径作为key，以RecordReader.nextKeyValue()读取的一行（其实是整个文件）作为value</div><div class="line">			context.write(filenameKey, value);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public int run(String[] args) throws Exception &#123;</div><div class="line">		Configuration conf = new Configuration();</div><div class="line">		/*System.setProperty(&quot;HADOOP_USER_NAME&quot;, &quot;hadoop&quot;);*/</div><div class="line">		String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();</div><div class="line">		if (otherArgs.length != 2) &#123;</div><div class="line">			System.err.println(&quot;Usage: combinefiles &lt;in&gt; &lt;out&gt;&quot;);</div><div class="line">			System.exit(2);</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		Job job = Job.getInstance(conf,&quot;combine small files to sequencefile&quot;);</div><div class="line">		job.setJarByClass(SmallFilesToSequenceFileConverter.class);</div><div class="line">		</div><div class="line">		//默认是 TextInputFormat</div><div class="line">		job.setInputFormatClass(WholeFileInputFormat.class);</div><div class="line">		</div><div class="line">		/**</div><div class="line">		 * 这里没有指定reduce，所以会调用默认的reduce，但是如果输出的格式仍然是文本的话，那么value.toString()就会</div><div class="line">		 * 是一个对象的hash地址，所以这里指定输出value的格式为字节序列：SequenceFileOutputFormat</div><div class="line">		 * 这样输出的文件中的格式：文件名（key)	字节序列（value）</div><div class="line">		 * 问题：</div><div class="line">		 * 1.将所以的小文件最后都以 &quot; 文件名（key)	字节序列（value） &quot;的方式输出到了一个文件中，那么最后这个文件将非常的大</div><div class="line">		 * 2.最后输出的文件是字节文件，那么我们再不能使用默认的InputFormat的方式（TextInputformat）来读取文件了</div><div class="line">		 */</div><div class="line">		job.setOutputFormatClass(SequenceFileOutputFormat.class);</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(BytesWritable.class);</div><div class="line">		</div><div class="line">		job.setMapperClass(SequenceFileMapper.class);</div><div class="line">		</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line">		</div><div class="line">		return job.waitForCompletion(true) ? 0 : 1;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws Exception &#123;</div><div class="line">		args=new String[]&#123;&quot;c:/wordcount/smallinput&quot;,&quot;c:/wordcount/smallout&quot;&#125;;</div><div class="line">		int exitCode = ToolRunner.run(new SmallFilesToSequenceFileConverter(), args);</div><div class="line">		System.exit(exitCode);</div><div class="line">		</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/04/16/bigdata/hadoop/自定义InputFormat之大量小文件的问题/" data-id="cj290sbzo00rossqqng4y60g7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mapreduce/">mapreduce</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/04/16/bigdata/hadoop/自定义GroupingComparator/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          自定义GroupingComparator
        
      </div>
    </a>
  
  
    <a href="/2017/04/16/bigdata/hadoop/自定义可序列化的Bean/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">自定义可序列化的Bean</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/IDEA/">IDEA</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NFS/">NFS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tachyon/">Tachyon</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/azkaban/">azkaban</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/echarts/">echarts</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/flume/">flume</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hbase/">hbase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hive/">hive</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/inotify/">inotify</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kafka/">kafka</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/logstash/">logstash</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/markdown/">markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/memcached/">memcached</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mongodb/">mongodb</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/nginx/">nginx</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/">project</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/redis/">redis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/rsync/">rsync</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/scala/">scala</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/shell/">shell</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/socket/">socket</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/sqoop/">sqoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/storm/">storm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据仓库/">数据仓库</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/IDEA/">IDEA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux基础命令/">Linux基础命令</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux重要配置文件/">Linux重要配置文件</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NFS/">NFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NIO/">NIO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/azkaban/">azkaban</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/echarts/">echarts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hbase/">hbase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hive/">hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/inotify/">inotify</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/">kafka</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/logstash/">logstash</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mapreduce/">mapreduce</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/">markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memcached/">memcached</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/">mongodb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/netty/">netty</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nginx/">nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/project/">project</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rpc/">rpc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rsync/">rsync</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala/">scala</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala函数式编程/">scala函数式编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala编程/">scala编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/">shell</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/socket/">socket</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqoop/">sqoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/storm/">storm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/zookeeper/">zookeeper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据仓库/">数据仓库</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/IDEA/" style="font-size: 10px;">IDEA</a> <a href="/tags/Linux基础命令/" style="font-size: 19.52px;">Linux基础命令</a> <a href="/tags/Linux重要配置文件/" style="font-size: 14.76px;">Linux重要配置文件</a> <a href="/tags/NFS/" style="font-size: 10px;">NFS</a> <a href="/tags/NIO/" style="font-size: 11.43px;">NIO</a> <a href="/tags/azkaban/" style="font-size: 10.48px;">azkaban</a> <a href="/tags/echarts/" style="font-size: 10.95px;">echarts</a> <a href="/tags/flume/" style="font-size: 10.95px;">flume</a> <a href="/tags/hadoop/" style="font-size: 18.57px;">hadoop</a> <a href="/tags/hbase/" style="font-size: 13.33px;">hbase</a> <a href="/tags/hive/" style="font-size: 18.1px;">hive</a> <a href="/tags/inotify/" style="font-size: 10px;">inotify</a> <a href="/tags/java/" style="font-size: 12.38px;">java</a> <a href="/tags/kafka/" style="font-size: 12.86px;">kafka</a> <a href="/tags/linux/" style="font-size: 13.33px;">linux</a> <a href="/tags/logstash/" style="font-size: 10.48px;">logstash</a> <a href="/tags/mapreduce/" style="font-size: 16.67px;">mapreduce</a> <a href="/tags/markdown/" style="font-size: 10px;">markdown</a> <a href="/tags/memcached/" style="font-size: 13.81px;">memcached</a> <a href="/tags/mongodb/" style="font-size: 14.76px;">mongodb</a> <a href="/tags/mysql/" style="font-size: 17.14px;">mysql</a> <a href="/tags/netty/" style="font-size: 10.95px;">netty</a> <a href="/tags/nginx/" style="font-size: 14.29px;">nginx</a> <a href="/tags/project/" style="font-size: 10.48px;">project</a> <a href="/tags/python/" style="font-size: 19.05px;">python</a> <a href="/tags/redis/" style="font-size: 17.14px;">redis</a> <a href="/tags/rpc/" style="font-size: 10.48px;">rpc</a> <a href="/tags/rsync/" style="font-size: 10px;">rsync</a> <a href="/tags/scala/" style="font-size: 17.62px;">scala</a> <a href="/tags/scala函数式编程/" style="font-size: 11.9px;">scala函数式编程</a> <a href="/tags/scala编程/" style="font-size: 15.71px;">scala编程</a> <a href="/tags/shell/" style="font-size: 17.62px;">shell</a> <a href="/tags/socket/" style="font-size: 11.9px;">socket</a> <a href="/tags/spark/" style="font-size: 20px;">spark</a> <a href="/tags/sqoop/" style="font-size: 10.95px;">sqoop</a> <a href="/tags/storm/" style="font-size: 15.24px;">storm</a> <a href="/tags/zookeeper/" style="font-size: 16.19px;">zookeeper</a> <a href="/tags/数据仓库/" style="font-size: 11.43px;">数据仓库</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/05/02/bigdata/spark从入门到精通_笔记/Tachyon/">Tachyon</a>
          </li>
        
          <li>
            <a href="/2017/04/30/数据仓库/数据仓库2/">数据仓库</a>
          </li>
        
          <li>
            <a href="/2017/04/29/IDEA/IDEA/">IDEA</a>
          </li>
        
          <li>
            <a href="/2017/04/29/数据仓库/ETL/">ETL</a>
          </li>
        
          <li>
            <a href="/2017/04/28/数据仓库/PowderDesigner/">PowderDesigner的使用</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Mr. Chen<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>




  </div>
</body>
</html>