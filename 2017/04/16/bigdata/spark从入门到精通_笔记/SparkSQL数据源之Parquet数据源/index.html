<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>SparkSQL数据源之Parquet数据源 | Chen&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="数据源Parquet的介绍Parquet是面向分析性业务的列式存储格式,由Twitter和Cloudera合作开发,2015年5月从Apache的孵化器里毕业成为Apache顶级项目 列式存储和行式存储相比有哪些优势呢?1.可以跳过不符合条件的数据,制只读取需要的数据,降低IO数据量2.压缩编码可以降低磁盘存储空间,由于同一列的数据类型是一样的,可以使用更高效的压缩编码(例如:Run Length">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="SparkSQL数据源之Parquet数据源">
<meta property="og:url" content="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkSQL数据源之Parquet数据源/index.html">
<meta property="og:site_name" content="Chen's Blog">
<meta property="og:description" content="数据源Parquet的介绍Parquet是面向分析性业务的列式存储格式,由Twitter和Cloudera合作开发,2015年5月从Apache的孵化器里毕业成为Apache顶级项目 列式存储和行式存储相比有哪些优势呢?1.可以跳过不符合条件的数据,制只读取需要的数据,降低IO数据量2.压缩编码可以降低磁盘存储空间,由于同一列的数据类型是一样的,可以使用更高效的压缩编码(例如:Run Length">
<meta property="og:updated_time" content="2017-04-22T07:23:06.192Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SparkSQL数据源之Parquet数据源">
<meta name="twitter:description" content="数据源Parquet的介绍Parquet是面向分析性业务的列式存储格式,由Twitter和Cloudera合作开发,2015年5月从Apache的孵化器里毕业成为Apache顶级项目 列式存储和行式存储相比有哪些优势呢?1.可以跳过不符合条件的数据,制只读取需要的数据,降低IO数据量2.压缩编码可以降低磁盘存储空间,由于同一列的数据类型是一样的,可以使用更高效的压缩编码(例如:Run Length">
  
    <link rel="alternate" href="/atom.xml" title="Chen&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Chen&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一个技术渣的自说自话</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-bigdata/spark从入门到精通_笔记/SparkSQL数据源之Parquet数据源" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkSQL数据源之Parquet数据源/" class="article-date">
  <time datetime="2017-04-16T04:47:25.203Z" itemprop="datePublished">2017-04-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      SparkSQL数据源之Parquet数据源
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="数据源Parquet的介绍"><a href="#数据源Parquet的介绍" class="headerlink" title="数据源Parquet的介绍"></a>数据源Parquet的介绍</h1><p>Parquet是面向分析性业务的列式存储格式,由Twitter和Cloudera合作开发,2015年5月从Apache的孵化器里毕业成为Apache顶级项目</p>
<p>列式存储和行式存储相比有哪些优势呢?<br>1.可以跳过不符合条件的数据,制只读取需要的数据,降低IO数据量<br>2.压缩编码可以降低磁盘存储空间,由于同一列的数据类型是一样的,可以使用更高效的压缩编码(例如:Run Length Encoding和Delta Encoding)进一步节约存储空间<br>3.只读取需要的列,支持向量运算,能够获取更好的扫描性能</p>
<h1 id="数据源Parquet的编程方式加载数据"><a href="#数据源Parquet的编程方式加载数据" class="headerlink" title="数据源Parquet的编程方式加载数据"></a>数据源Parquet的编程方式加载数据</h1><p>下面介绍的是Parquet数据源,使用编程的方式加载Parquet文件中的数据</p>
<p>案例:查询用户数据中的用户名<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">val sparkConf = new SparkConf().setAppName(&quot;dataFrame&quot;).setMaster(&quot;local&quot;)</div><div class="line">val sc = new SparkContext(sparkConf)</div><div class="line">val sqlContext = new SQLContext(sc)</div><div class="line"></div><div class="line">// 使用format(&quot;parquet&quot;).load()是通用的方式</div><div class="line">//val userDF = sqlContext.read.format(&quot;parquet&quot;).load(&quot;C:\\Users\\Administrator\\Desktop\\users.parquet&quot;)</div><div class="line">// parquet()是针对parquet文件具体的读取,例如对于json文件,就有sqlContext.read.json();cvs,jdbc等是一样的</div><div class="line">val userDF = sqlContext.read.parquet(&quot;C:\\Users\\Administrator\\Desktop\\users.parquet&quot;)</div><div class="line"></div><div class="line">// 将DataFrame注册为临时表,然后使用sql查询需要的数据</div><div class="line">userDF.registerTempTable(&quot;users&quot;)</div><div class="line">val userNameDF = sqlContext.sql(&quot;select name from users&quot;)</div><div class="line"></div><div class="line">//对查询出来的DataFrame进行Transformation操作,然后打印</div><div class="line">// 在进行DF到rdd的转换的时候,一行数据转成rdd就是一个Array,所以用()去取数组元素</div><div class="line">val userName = userNameDF.rdd.map(row=&gt;row(0).toString+&quot;-xxx&quot;)</div><div class="line">userName.foreach(println)</div><div class="line"></div><div class="line">/*打印结果:</div><div class="line">  Alyssa-xxx</div><div class="line">  Ben-xxx</div><div class="line"> */</div></pre></td></tr></table></figure></p>
<h1 id="Parquet数据源的自动分区推断"><a href="#Parquet数据源的自动分区推断" class="headerlink" title="Parquet数据源的自动分区推断"></a>Parquet数据源的自动分区推断</h1><p>表分区是一种常见的优化方式,比如hive中就提供了表分区的特性,在一个分区表中,不同分区的数据通常存储在不同的目录中,分区列的值通常就包含在了分区目录的目录名中,spark sql中的Parquet数据源支持自动根据目录名推断出分区信息,例如,如果将入口数据存储在分区表中,并且使用性别和国家作为分区列,那么目录结构可能如下所以:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">tableName</div><div class="line">	|--gender=male</div><div class="line">		|--country=US</div><div class="line">			....</div><div class="line">		|--country=CN</div><div class="line">			....</div><div class="line"></div><div class="line">	|--gender=female</div><div class="line">		|--country=US</div><div class="line">			....</div><div class="line">		|--country=CN</div><div class="line">			....</div></pre></td></tr></table></figure>
<p>如果将/tableName传入SQLContext.read.Parquet()或者SQLContext.read.load()方法,那么spark sql就会自动根据目录结构,推断出分区信息,是gender和country,即使数据文件中只包含了两列值:name和age,但是spark sql返回的DataFrame,调用printSchema()方法时,会打印四个列的值:name,age,country,gender,这就是自动分区推断你的功能</p>
<p>此外,分区列的数据类型,也是自动被推断出来的,目前,spark sql仅支持自动推断出数字类型和字符串类型,有时,用户也许不希望spark sql自动推断分区列的数据类型,此时只要设置一个配置即可,spark.sql.source.partitionColumnTypeInference.enabled,默认为true,即:自动推断分区列的类型,设置为false,即不糊自动推断类型,禁止自动推断分区列的类型时,所有分区列的类型就统一默认都是String</p>
<p>案例:自动推断用户数据的性别和国家</p>
<p>创建目录并上传Parquet文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir /spark-study/users</div><div class="line">hadoop fs -mkdir /spark-study/users/gender=male</div><div class="line">hadoop fs -mkdir /spark-study/users/gender=male/country=US</div><div class="line">hadoop fs -put users.parquet /spark-study/users/gender=male/country=US/users.parquet</div></pre></td></tr></table></figure></p>
<p>测试<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">val sparkConf = new SparkConf().setAppName(&quot;dataFrame&quot;).setMaster(&quot;local&quot;)</div><div class="line">val sc = new SparkContext(sparkConf)</div><div class="line">val sqlContext = new SQLContext(sc)</div><div class="line"></div><div class="line">val userDF = sqlContext.read.parquet(&quot;C:\\Users\\Administrator\\Desktop\\users\\gender=male\\country=US\\users.parquet&quot;)</div><div class="line">userDF.printSchema()</div><div class="line">userDF.show</div></pre></td></tr></table></figure></p>
<h1 id="Parquet数据源之合并元数据"><a href="#Parquet数据源之合并元数据" class="headerlink" title="Parquet数据源之合并元数据"></a>Parquet数据源之合并元数据</h1><p>如同ProtocolBuffer,Avro,Thrift一样,Parquet也是支持元数据的合并的,用户可以在一开始就定义一个简单的元数据,然后随着业务需要,逐渐往元数据中添加更多的列,在这种情况下,用户可能会创建多个Parquet文件,有着多个不同的但是却相互兼容的元数据,Parquet数据源支持自动推断出这种情况,并且进行多个Parquet文件的元数据的合并</p>
<p>因为元数据合并是一种相对耗时的操作,而且在大多数情况下不是一种必要的特性,从spark 1.5.0版本开始,默认是关闭Parquet文件的自动合并元数据的特性的,可以通过以下的两种方式开启Parquet数据源的自动合并元数据的特性:<br>1.读取parquet文件时,将数据源的选项,mergeSchema设置为true<br>2.使用SQLContext.setConf()方法,将”spark.sql.parquet.mergeSchema”参数设置为true</p>
<p>案例:合并学生的基本信息和成绩信息的元数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"> val sparkConf = new SparkConf().setAppName(&quot;dataFrame&quot;).setMaster(&quot;local&quot;)</div><div class="line"> val sc = new SparkContext(sparkConf)</div><div class="line"> val sqlContext = new SQLContext(sc)</div><div class="line"></div><div class="line"> import sqlContext.implicits._</div><div class="line"></div><div class="line"> // 首先手动创建一个DataFrame,作为学生的基本信息数据,并将其写入到一个Parquet文件中</div><div class="line"> val studentWithNameAge = Array((&quot;leo&quot;,23),(&quot;jack&quot;,25))</div><div class="line"> val studentWithNameAgeDF = sc.parallelize(studentWithNameAge).toDF(&quot;name&quot;, &quot;age&quot;)</div><div class="line"> studentWithNameAgeDF.write.save(&quot;C:\\Users\\Administrator\\Desktop\\student&quot;, SaveMode.Append)</div><div class="line"></div><div class="line"> //创建第二个DataFrame,作为学生的成绩信息,并写入一个Parquet文件中</div><div class="line"> val studentWithNameGrade = Array((&quot;marry&quot;,&quot;A&quot;),(&quot;tom&quot;,&quot;B&quot;))</div><div class="line"> val studentWithNameGradeDF = sc.parallelize(studentWithNameGrade).toDF(&quot;name&quot;, &quot;grade&quot;)</div><div class="line"> studentWithNameGradeDF.write.save(&quot;C:\\Users\\Administrator\\Desktop\\student&quot;, SaveMode.Append)</div><div class="line"></div><div class="line"> /*</div><div class="line"> 第一个DataFrame的元数据和第二个DataFrame的元数据是不相同的,</div><div class="line"> 第一个包含了name和age两个列,第二个包含了name和grade两个列</div><div class="line"> 所以,这里期望的是,读取出来的表数据,自动合并两个问价你的元数据,</div><div class="line"> 出现3个列:name,age,grade</div><div class="line">  */</div><div class="line"> val studentDF = sqlContext.read.option(&quot;mergeSchema&quot;, true).parquet(&quot;C:\\Users\\Administrator\\Desktop\\student&quot;)</div><div class="line"> studentDF.printSchema()</div><div class="line"> studentDF.show</div><div class="line"></div><div class="line"></div><div class="line">// 注意在spark1.5.0上是可以的,在spark2.1.0上不行,编译就报错</div></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkSQL数据源之Parquet数据源/" data-id="cj290sc7g00zcssqq915pc4sb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkSQL数据源之json数据源/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          SparkSQL数据源之json数据源
        
      </div>
    </a>
  
  
    <a href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkSQL的前世今生/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">SparkSQL的前世今生</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/IDEA/">IDEA</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NFS/">NFS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tachyon/">Tachyon</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/azkaban/">azkaban</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/echarts/">echarts</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/flume/">flume</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hbase/">hbase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hive/">hive</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/inotify/">inotify</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kafka/">kafka</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/logstash/">logstash</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/markdown/">markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/memcached/">memcached</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mongodb/">mongodb</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/nginx/">nginx</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/">project</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/redis/">redis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/rsync/">rsync</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/scala/">scala</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/shell/">shell</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/socket/">socket</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/sqoop/">sqoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/storm/">storm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据仓库/">数据仓库</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/IDEA/">IDEA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux基础命令/">Linux基础命令</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux重要配置文件/">Linux重要配置文件</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NFS/">NFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NIO/">NIO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/azkaban/">azkaban</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/echarts/">echarts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hbase/">hbase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hive/">hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/inotify/">inotify</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/">kafka</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/logstash/">logstash</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mapreduce/">mapreduce</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/">markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memcached/">memcached</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/">mongodb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/netty/">netty</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nginx/">nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/project/">project</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rpc/">rpc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rsync/">rsync</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala/">scala</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala函数式编程/">scala函数式编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala编程/">scala编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/">shell</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/socket/">socket</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqoop/">sqoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/storm/">storm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/zookeeper/">zookeeper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据仓库/">数据仓库</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/IDEA/" style="font-size: 10px;">IDEA</a> <a href="/tags/Linux基础命令/" style="font-size: 19.52px;">Linux基础命令</a> <a href="/tags/Linux重要配置文件/" style="font-size: 14.76px;">Linux重要配置文件</a> <a href="/tags/NFS/" style="font-size: 10px;">NFS</a> <a href="/tags/NIO/" style="font-size: 11.43px;">NIO</a> <a href="/tags/azkaban/" style="font-size: 10.48px;">azkaban</a> <a href="/tags/echarts/" style="font-size: 10.95px;">echarts</a> <a href="/tags/flume/" style="font-size: 10.95px;">flume</a> <a href="/tags/hadoop/" style="font-size: 18.57px;">hadoop</a> <a href="/tags/hbase/" style="font-size: 13.33px;">hbase</a> <a href="/tags/hive/" style="font-size: 18.1px;">hive</a> <a href="/tags/inotify/" style="font-size: 10px;">inotify</a> <a href="/tags/java/" style="font-size: 12.38px;">java</a> <a href="/tags/kafka/" style="font-size: 12.86px;">kafka</a> <a href="/tags/linux/" style="font-size: 13.33px;">linux</a> <a href="/tags/logstash/" style="font-size: 10.48px;">logstash</a> <a href="/tags/mapreduce/" style="font-size: 16.67px;">mapreduce</a> <a href="/tags/markdown/" style="font-size: 10px;">markdown</a> <a href="/tags/memcached/" style="font-size: 13.81px;">memcached</a> <a href="/tags/mongodb/" style="font-size: 14.76px;">mongodb</a> <a href="/tags/mysql/" style="font-size: 17.14px;">mysql</a> <a href="/tags/netty/" style="font-size: 10.95px;">netty</a> <a href="/tags/nginx/" style="font-size: 14.29px;">nginx</a> <a href="/tags/project/" style="font-size: 10.48px;">project</a> <a href="/tags/python/" style="font-size: 19.05px;">python</a> <a href="/tags/redis/" style="font-size: 17.14px;">redis</a> <a href="/tags/rpc/" style="font-size: 10.48px;">rpc</a> <a href="/tags/rsync/" style="font-size: 10px;">rsync</a> <a href="/tags/scala/" style="font-size: 17.62px;">scala</a> <a href="/tags/scala函数式编程/" style="font-size: 11.9px;">scala函数式编程</a> <a href="/tags/scala编程/" style="font-size: 15.71px;">scala编程</a> <a href="/tags/shell/" style="font-size: 17.62px;">shell</a> <a href="/tags/socket/" style="font-size: 11.9px;">socket</a> <a href="/tags/spark/" style="font-size: 20px;">spark</a> <a href="/tags/sqoop/" style="font-size: 10.95px;">sqoop</a> <a href="/tags/storm/" style="font-size: 15.24px;">storm</a> <a href="/tags/zookeeper/" style="font-size: 16.19px;">zookeeper</a> <a href="/tags/数据仓库/" style="font-size: 11.43px;">数据仓库</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/05/02/bigdata/spark从入门到精通_笔记/Tachyon/">Tachyon</a>
          </li>
        
          <li>
            <a href="/2017/04/30/数据仓库/数据仓库2/">数据仓库</a>
          </li>
        
          <li>
            <a href="/2017/04/29/IDEA/IDEA/">IDEA</a>
          </li>
        
          <li>
            <a href="/2017/04/29/数据仓库/ETL/">ETL</a>
          </li>
        
          <li>
            <a href="/2017/04/28/数据仓库/PowderDesigner/">PowderDesigner的使用</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Mr. Chen<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>




  </div>
</body>
</html>