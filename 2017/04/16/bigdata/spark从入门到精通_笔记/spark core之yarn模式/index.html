<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>spark core之yarn模式 | Chen&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="yarn-client模式原理 yarn-cluster模式原理 yarn-client模式提交spark作业yarn运行spark作业的前提如果想要让spark作业可以运行在yarn上面,那么首先就必须在spark-env.sh文件中,配置HADOOP_CONF_DIR或者YARN_CONF_DIR属性,值为hadoop的配置文件的目录,即:HADOOP_HOME/etc/hadoop,其中包含">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="spark core之yarn模式">
<meta property="og:url" content="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/spark core之yarn模式/index.html">
<meta property="og:site_name" content="Chen's Blog">
<meta property="og:description" content="yarn-client模式原理 yarn-cluster模式原理 yarn-client模式提交spark作业yarn运行spark作业的前提如果想要让spark作业可以运行在yarn上面,那么首先就必须在spark-env.sh文件中,配置HADOOP_CONF_DIR或者YARN_CONF_DIR属性,值为hadoop的配置文件的目录,即:HADOOP_HOME/etc/hadoop,其中包含">
<meta property="og:image" content="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/yarn-client模式原理.png">
<meta property="og:image" content="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/yarn-cluster模式原理.png">
<meta property="og:updated_time" content="2017-04-22T07:23:06.066Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="spark core之yarn模式">
<meta name="twitter:description" content="yarn-client模式原理 yarn-cluster模式原理 yarn-client模式提交spark作业yarn运行spark作业的前提如果想要让spark作业可以运行在yarn上面,那么首先就必须在spark-env.sh文件中,配置HADOOP_CONF_DIR或者YARN_CONF_DIR属性,值为hadoop的配置文件的目录,即:HADOOP_HOME/etc/hadoop,其中包含">
<meta name="twitter:image" content="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/yarn-client模式原理.png">
  
    <link rel="alternate" href="/atom.xml" title="Chen&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Chen&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一个技术渣的自说自话</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-bigdata/spark从入门到精通_笔记/spark core之yarn模式" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/04/16/bigdata/spark从入门到精通_笔记/spark core之yarn模式/" class="article-date">
  <time datetime="2017-04-16T04:47:25.175Z" itemprop="datePublished">2017-04-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      spark core之yarn模式
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="yarn-client模式原理"><a href="#yarn-client模式原理" class="headerlink" title="yarn-client模式原理"></a>yarn-client模式原理</h1><p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/yarn-client模式原理.png" alt=""></p>
<h1 id="yarn-cluster模式原理"><a href="#yarn-cluster模式原理" class="headerlink" title="yarn-cluster模式原理"></a>yarn-cluster模式原理</h1><p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/yarn-cluster模式原理.png" alt=""></p>
<h1 id="yarn-client模式提交spark作业"><a href="#yarn-client模式提交spark作业" class="headerlink" title="yarn-client模式提交spark作业"></a>yarn-client模式提交spark作业</h1><h2 id="yarn运行spark作业的前提"><a href="#yarn运行spark作业的前提" class="headerlink" title="yarn运行spark作业的前提"></a>yarn运行spark作业的前提</h2><p>如果想要让spark作业可以运行在yarn上面,那么首先就必须在spark-env.sh文件中,配置HADOOP_CONF_DIR或者YARN_CONF_DIR属性,值为hadoop的配置文件的目录,即:HADOOP_HOME/etc/hadoop,其中包含了hadoop和yarn所有的配置文件,比如:hdfs-site.xml,yarn-site.xml等,spark需要这些配置来读写HDFS,以及连接到yarn ResourceManager上,这个目录中包含的配置文件都会被分发到yarn集群中去的</p>
<p>vim spark/conf/spark-env.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop</div><div class="line"></div><div class="line">/*在/usr/local/hadoop/etc/hadoop目录下有:</div><div class="line">yarn-site.xml(其中可以找到ResourceManager所在的机器)</div><div class="line">还有一些其他的配置文件</div><div class="line">*/</div></pre></td></tr></table></figure></p>
<p>跟spark standalone模式不同,通常不需要使用–master指定master URL<br>因为spark会从hadoop的配置文件中去读ResourceManager的配置,这样就知道了ResourceManager所在的机器(master),所以不需要我们指定,但是我们需要指定deploy mode,如下示例:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">/export/servers/spark/bin/spark-submit \</div><div class="line">--class cn.spark.study.core.WordCount \</div><div class="line">--master yarn-cluster</div><div class="line">#--master yarn-client</div><div class="line">--num-executors 1 \</div><div class="line">--driver-memory 100m \</div><div class="line">--executor-memory 100m \</div><div class="line">--executor-cores 1 \</div><div class="line">--queue hadoop队列</div><div class="line">/usr/xx/spark-study-java-0.0.1-SNAPSHOT-jar-with-dependencies.jar \</div></pre></td></tr></table></figure></p>
<p>–queue,在不同的部门,或者是不同的大数据项目,共用一个yarn集群,运行spark作业,推荐一定要用–queue,指定不同的hadoop队列,做项目或者部门之间的队列隔离</p>
<p>与Standalone模式类似,yarn-client模式通常建议在测试的时候使用,方便你直接在提交作业的机器上查看日志,但是作业实际部署到生产环境中进行运行的时候,还是使用yarn-cluster模式</p>
<p>yarn模式下需要观察的点:<br>1.日志<br>命令行日志<br>web ui日志</p>
<p>2.web ui的地址不再是spark://192.168.0.108:8080这种URL了,因为那是Standalone模式下的监控web ui,在yarn模式下,要看yarn的web ui: <a href="http://192.168.0.108:8088/" target="_blank" rel="external">http://192.168.0.108:8088/</a> 这是yarn的URL地址</p>
<p>3.进程<br>driver是什么进程</p>
<p>AppLicationMaster是什么进程</p>
<p>executor进程</p>
<h1 id="yarn模式下的日志查看"><a href="#yarn模式下的日志查看" class="headerlink" title="yarn模式下的日志查看"></a>yarn模式下的日志查看</h1><p>在yarn模式下,spark作业运行相关的executor和ApplicationMaster都是运行在yarn的container中的,一个作业运行完了以后,yarn有两种方式来处理spark作业打印出的日志</p>
<p>1.聚合日志方式(推荐,比较常用)<br>这种格式将散落在集群中各个机器上的日志,最后都给聚合起来,让我们可以统一查看,如果yarn的日志聚合的选项打开了,即:yarn.log-aggregation-enable(yarn-site.xml文件中配置), container的日志会拷贝到HDFS上去,并从机器中删除</p>
<p>然后我们使用yarn logs -applicationId <app id=""> 命令来查看日志(app Id在yarn的web ui上看:resourceManager_host:8088)</app></p>
<p>yarn logs命令,会打印出application对应的所有container的日志出来,当然,因为日志是在HDFS上的,我们自然可以通过HDFS的命令行来直接从HDFS中查看日志,日志在HDFS中的目录,可以通过查看yarn.nodemanager.remote-app-log-dir和yarn.nodemanager.remote-app-log-dir-suffix属性来获知</p>
<p>2.web ui<br>日志也可以通过spark web ui来查看executor的输出日志<br>但是此时需要启动History Server,需要让spark history server和mapreduce history server运行着;并且在yarn-site.xml文件中,配置yarn.log.server.url属性<br>spark history server web ui中的log url,会将你重新定向到mapreduce history server上去查看日志</p>
<p>3.分散查看(通常不推荐)<br>如果没有打开聚合日志选项,那么日志默认就是散落在各个机器上的本次磁盘目录中的,在YARN_APP_LOGS_DIR目录下,根据hadoop版本的不同,通常在/tmp/logs目录下,或者在$HADOOP_HOME/logs/userlogs目录下,如果你要查看某个container的日志,那么就得登录到那台机器上去,然后到指定的目录下如,找到那个日志文件,然后才能查看</p>
<h1 id="yarn模式相关的参数"><a href="#yarn模式相关的参数" class="headerlink" title="yarn模式相关的参数"></a>yarn模式相关的参数</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">yarn模式运行spark作业所有属性详解</div><div class="line"></div><div class="line">属性名称											默认值							含义</div><div class="line">spark.yarn.am.memory								512m							client模式下，YARN Application Master使用的内存总量</div><div class="line">spark.yarn.am.cores									1								client模式下，Application Master使用的cpu数量</div><div class="line">spark.driver.cores									1								cluster模式下，driver使用的cpu core数量，driver与Application Master运行在一个进程中，所以也控制了Application Master的cpu数量</div><div class="line">spark.yarn.am.waitTime								100s							cluster模式下，Application Master要等待SparkContext初始化的时长; client模式下，application master等待driver来连接它的时长</div><div class="line">spark.yarn.submit.file.replication					hdfs副本数						作业写到hdfs上的文件的副本数量，比如工程jar，依赖jar，配置文件等，最小一定是1</div><div class="line">spark.yarn.preserve.staging.files					false							如果设置为true，那么在作业运行完之后，会避免工程jar等文件被删除掉</div><div class="line">spark.yarn.scheduler.heartbeat.interval-ms			3000							application master向resourcemanager发送心跳的间隔，单位ms</div><div class="line">spark.yarn.scheduler.initial-allocation.interval	200ms							application master在有pending住的container分配需求时，立即向resourcemanager发送心跳的间隔</div><div class="line">spark.yarn.max.executor.failures					executor数量*2，最小3			整个作业判定为失败之前，executor最大的失败次数</div><div class="line">spark.yarn.historyServer.address					无								spark history server的地址</div><div class="line">spark.yarn.dist.archives							无								每个executor都要获取并放入工作目录的archive</div><div class="line">spark.yarn.dist.files								无								每个executor都要放入的工作目录的文件</div><div class="line">spark.executor.instances							2								默认的executor数量</div><div class="line">spark.yarn.executor.memoryOverhead					executor内存10%					每个executor的堆外内存大小，用来存放诸如常量字符串等东西</div><div class="line">spark.yarn.driver.memoryOverhead					driver内存7%					同上</div><div class="line">spark.yarn.am.memoryOverhead						AM内存7%						同上</div><div class="line">spark.yarn.am.port									随机							application master端口</div><div class="line">spark.yarn.jar										无								spark jar文件的位置</div><div class="line">spark.yarn.access.namenodes							无								spark作业能访问的hdfs namenode地址</div><div class="line">spark.yarn.containerLauncherMaxThreads				25								application master能用来启动executor container的最大线程数量</div><div class="line">spark.yarn.am.extraJavaOptions						无								application master的jvm参数</div><div class="line">spark.yarn.am.extraLibraryPath						无								application master的额外库路径</div><div class="line">spark.yarn.maxAppAttempts															提交spark作业最大的尝试次数</div><div class="line">spark.yarn.submit.waitAppCompletion					true							cluster模式下，client是否等到作业运行完再退出</div></pre></td></tr></table></figure>
<p>以上这些参数可以在spark-submit中配置,使用–conf配置</p>
<h1 id="spark-submit详解"><a href="#spark-submit详解" class="headerlink" title="spark-submit详解"></a>spark-submit详解</h1><p>spark-submit可以通过一个统一的接口,将spark应用程序提交到所有spark支持的集群管理器上(Standalone(mater),Yarn(ResourceManager)等),所以我们并不需要为每种集群管理器都做特殊的配置</p>
<p>–master<br>1.如果不设置,那么就是local模式<br>2.如果设置spark://开头的URL,那么就是Standalone模式,会提交到指定的URL的Mater进程上去<br>3.如果设置yarn-client/yarn-cluster,那么就是yarn模式,会读取hadoop配置文件,然后连接ResourceManager</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/spark core之yarn模式/" data-id="cj290scbm0131ssqqok9n643p" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/04/16/bigdata/spark从入门到精通_笔记/spark core之worker节点配置以及spark-env.sh参数详解/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          spark core之worker节点配置以及spark-env.sh参数详解
        
      </div>
    </a>
  
  
    <a href="/2017/04/16/bigdata/spark从入门到精通_笔记/spark core之主要的几个术语/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">spark core之主要的几个术语</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/IDEA/">IDEA</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NFS/">NFS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tachyon/">Tachyon</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/azkaban/">azkaban</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/echarts/">echarts</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/flume/">flume</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hbase/">hbase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hive/">hive</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/inotify/">inotify</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kafka/">kafka</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/logstash/">logstash</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/markdown/">markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/memcached/">memcached</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mongodb/">mongodb</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/nginx/">nginx</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/">project</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/redis/">redis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/rsync/">rsync</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/scala/">scala</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/shell/">shell</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/socket/">socket</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/sqoop/">sqoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/storm/">storm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据仓库/">数据仓库</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/IDEA/">IDEA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux基础命令/">Linux基础命令</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux重要配置文件/">Linux重要配置文件</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NFS/">NFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NIO/">NIO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/azkaban/">azkaban</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/echarts/">echarts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hbase/">hbase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hive/">hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/inotify/">inotify</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/">kafka</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/logstash/">logstash</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mapreduce/">mapreduce</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/">markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memcached/">memcached</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/">mongodb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/netty/">netty</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nginx/">nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/project/">project</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rpc/">rpc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rsync/">rsync</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala/">scala</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala函数式编程/">scala函数式编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala编程/">scala编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/">shell</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/socket/">socket</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqoop/">sqoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/storm/">storm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/zookeeper/">zookeeper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据仓库/">数据仓库</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/IDEA/" style="font-size: 10px;">IDEA</a> <a href="/tags/Linux基础命令/" style="font-size: 19.52px;">Linux基础命令</a> <a href="/tags/Linux重要配置文件/" style="font-size: 14.76px;">Linux重要配置文件</a> <a href="/tags/NFS/" style="font-size: 10px;">NFS</a> <a href="/tags/NIO/" style="font-size: 11.43px;">NIO</a> <a href="/tags/azkaban/" style="font-size: 10.48px;">azkaban</a> <a href="/tags/echarts/" style="font-size: 10.95px;">echarts</a> <a href="/tags/flume/" style="font-size: 10.95px;">flume</a> <a href="/tags/hadoop/" style="font-size: 18.57px;">hadoop</a> <a href="/tags/hbase/" style="font-size: 13.33px;">hbase</a> <a href="/tags/hive/" style="font-size: 18.1px;">hive</a> <a href="/tags/inotify/" style="font-size: 10px;">inotify</a> <a href="/tags/java/" style="font-size: 12.38px;">java</a> <a href="/tags/kafka/" style="font-size: 12.86px;">kafka</a> <a href="/tags/linux/" style="font-size: 13.33px;">linux</a> <a href="/tags/logstash/" style="font-size: 10.48px;">logstash</a> <a href="/tags/mapreduce/" style="font-size: 16.67px;">mapreduce</a> <a href="/tags/markdown/" style="font-size: 10px;">markdown</a> <a href="/tags/memcached/" style="font-size: 13.81px;">memcached</a> <a href="/tags/mongodb/" style="font-size: 14.76px;">mongodb</a> <a href="/tags/mysql/" style="font-size: 17.14px;">mysql</a> <a href="/tags/netty/" style="font-size: 10.95px;">netty</a> <a href="/tags/nginx/" style="font-size: 14.29px;">nginx</a> <a href="/tags/project/" style="font-size: 10.48px;">project</a> <a href="/tags/python/" style="font-size: 19.05px;">python</a> <a href="/tags/redis/" style="font-size: 17.14px;">redis</a> <a href="/tags/rpc/" style="font-size: 10.48px;">rpc</a> <a href="/tags/rsync/" style="font-size: 10px;">rsync</a> <a href="/tags/scala/" style="font-size: 17.62px;">scala</a> <a href="/tags/scala函数式编程/" style="font-size: 11.9px;">scala函数式编程</a> <a href="/tags/scala编程/" style="font-size: 15.71px;">scala编程</a> <a href="/tags/shell/" style="font-size: 17.62px;">shell</a> <a href="/tags/socket/" style="font-size: 11.9px;">socket</a> <a href="/tags/spark/" style="font-size: 20px;">spark</a> <a href="/tags/sqoop/" style="font-size: 10.95px;">sqoop</a> <a href="/tags/storm/" style="font-size: 15.24px;">storm</a> <a href="/tags/zookeeper/" style="font-size: 16.19px;">zookeeper</a> <a href="/tags/数据仓库/" style="font-size: 11.43px;">数据仓库</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/05/02/bigdata/spark从入门到精通_笔记/Tachyon/">Tachyon</a>
          </li>
        
          <li>
            <a href="/2017/04/30/数据仓库/数据仓库2/">数据仓库</a>
          </li>
        
          <li>
            <a href="/2017/04/29/IDEA/IDEA/">IDEA</a>
          </li>
        
          <li>
            <a href="/2017/04/29/数据仓库/ETL/">ETL</a>
          </li>
        
          <li>
            <a href="/2017/04/28/数据仓库/PowderDesigner/">PowderDesigner的使用</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Mr. Chen<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>




  </div>
</body>
</html>