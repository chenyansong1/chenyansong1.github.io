<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="一个技术渣的自说自话">
<meta property="og:type" content="website">
<meta property="og:title" content="Chen's Blog">
<meta property="og:url" content="http://yoursite.com/page/42/index.html">
<meta property="og:site_name" content="Chen's Blog">
<meta property="og:description" content="一个技术渣的自说自话">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chen's Blog">
<meta name="twitter:description" content="一个技术渣的自说自话">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"right","display":"always","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/42/"/>





  <title> Chen's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-right 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chen's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">一个技术渣的自说自话</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之架构原理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之架构原理/" itemprop="url">
                  SparkStreaming之架构原理
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/spark_streaming架构原理.png" alt=""></p>
<h1 id="StreamingContext的初始化与Receiver的启动原理"><a href="#StreamingContext的初始化与Receiver的启动原理" class="headerlink" title="StreamingContext的初始化与Receiver的启动原理"></a>StreamingContext的初始化与Receiver的启动原理</h1><p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/StreamingContext的初始化与Receiver的启动原理.png" alt=""></p>
<h1 id="SparkStreaming之数据接收原理和源码分析"><a href="#SparkStreaming之数据接收原理和源码分析" class="headerlink" title="SparkStreaming之数据接收原理和源码分析"></a>SparkStreaming之数据接收原理和源码分析</h1><p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/SparkStreaming之数据接收原理.png" alt=""></p>
<h1 id="数据处理原理剖析-block与batch关系"><a href="#数据处理原理剖析-block与batch关系" class="headerlink" title="数据处理原理剖析(block与batch关系)"></a>数据处理原理剖析(block与batch关系)</h1><p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/数据处理原理剖析.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之性能调优/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之性能调优/" itemprop="url">
                  SparkStreaming之性能调优
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据接收的并行度调优"><a href="#数据接收的并行度调优" class="headerlink" title="数据接收的并行度调优"></a>数据接收的并行度调优</h1><p>通过网络接收数据时(比如kafka,flume),会将数据反序列化,并存储在spark的内存中,如果数据接收称为系统的瓶颈,那么可以考虑并行化的数据接收,每一个输入DStream都会在某个Worker的Executor上,启动一个Receiver,该Receiver接收一个数据流,因此可以通过创建多个输入DStream,并且配置他们接收数据源不同的分区数据,达到多个数据流的效果,比如说,一个接收两个kafka topic的输入DStream,可以被拆分为两个DStream,每个分别接收一个topic的数据,这样就会创建两个Receiver,从而并行的接收数据,进而提升吞吐量,读个DStream可以使用union算子进行聚合,从而形成一个DStream,然后后续的Transformation算在操作都针对一个聚合后的DStream即可</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">int numStreams = 5</div><div class="line">List&lt;DStream&gt; kafkaStreams = new ArrayList&lt;DStream&gt;(numStreams)</div><div class="line"></div><div class="line">for(int i=0;i&lt;DStream; i++)&#123;</div><div class="line">	kafkaStreams.add(KafkaUtils.createStream(...))</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">unionedDStream = streamingContext.union(kafkaStreams.get(0),kafkaStreams.get(2)...)</div><div class="line"></div><div class="line"></div><div class="line">unionedDStream.print()</div></pre></td></tr></table></figure>
<p>数据接收并行度调优,除了创建更多输入DStream和Receiver以外,还可以考虑调节block interval参数,”spark.streaming.blockInterval”可以设置block interval(默认是200ms),对于大多数Receiver来说,在将接收到的数据保存到Spark的BlockManager之前,都会将数据切分为一个一个的block,而每个batch中的block数量,则决定了该batch对应的RDD的partition的数量,以及针对该RDD执行Transformation操作时,创建的task的数量,每个batch对应的task数量是可以大约估计的:<br>batch interval / (block interval)</p>
<p>例如说:batch interval为2s,block interval为200ms,会创建10个task,如果你认为每个batch的task的数量太少,即低于每台机器的cpu core数量,那么就说明batch的task数量是不够的,因为所有的cpu资源无法完全被利用起来,要为batch增加block的数量,那么就减小block interval,而然,推荐的block interval最小值是50ms,如果低于这个数值,那么大量task的启动时间,可能会变成一个性能开销点</p>
<p>除了上述说的两个提升设局接收并行度的方式,还有一种方法,技术显示的对输入数据流进行重分区,使用<br>inputStream.reparation(num of partitions)即可,这样就可以将接收到的batch,分布到指定的数量的机器上,然后再进行进一步的操作</p>
<h1 id="任务启动调优"><a href="#任务启动调优" class="headerlink" title="任务启动调优"></a>任务启动调优</h1><p>如果每秒钟启动的task过多,比如每秒启动50个,那么发送这些task到Worker节点上的Executor的性能开销会比较大,而且此时基本就很难达到毫秒级的延迟了,使用下面的操作可以减少这方面的性能开销;<br>1.Task序列化:使用Kryo序列化类库来序列化task,可以减小task的大小,从而减少发送这些task到各个Worker节点上的Executor的时间<br>2.执行模式:在Strandalone模式下,运行spark,可以达到更少的task启动时间</p>
<h1 id="数据处理的并行度调优"><a href="#数据处理的并行度调优" class="headerlink" title="数据处理的并行度调优"></a>数据处理的并行度调优</h1><p>如果在计算的任何stage中使用并行task的数量没有足够多,那么集群资源时无法被充分利用的,举例说:对于分布式的reduce操作,比如reduceByKey和reduceByKeyAndWindow,默认的并行task的数量是由”spark.default.parallelism”参数决定的,你可以在reduceByKey等操作中,传入第二个参数,手动指定该参数的并行度,也可以调节全局的”spark.default.parallelism”参数</p>
<h1 id="数据序列化的调优"><a href="#数据序列化的调优" class="headerlink" title="数据序列化的调优"></a>数据序列化的调优</h1><p>数据序列化造成的系统开销可以由序列化的优化来减小,在流式计算的场景下,有两种类型的数据需要序列化:<br>1.输入数据,默认情况下,接收到的输入数据,是存储在Executor的内存中的,使用的持久化级别是StorageLevel.MEMORY_AND_DISK_SER_2,这意味着,数据被序列化为字节从而减少GC开销,并且会复制以进行Executor失败的容错,因此数据首先会存储在内存中,然后在内存不足时会溢写到磁盘上,从而为流式计算来保存所有需要的数据,这里的序列化有明显的性能开销—Receiver必须反序列化从网络接收到的数据,然后再使用spark的序列化格式序列化数据</p>
<p>3.流式计算操作生成的持久化RDD,流式计算操作生成的持久化RDD可能会持久化到内存中,例如:窗口操作默认就会将数据持久化在内存章,因为这些数据后面可能会在多个窗口中被使用,并被处理多次,然而,不像spark core的默认持久化级别,StorageLevel.MEMORY_ONLY,流式计算操作生成的RDD的默认持久化级别是:StorageLevel.MEMORY_ONLY_SER,默认就会减小GC开销</p>
<p>在上述的场景中,使用Kryo序列化类库可以减小cpu和内存的性能开销,使用Kryo时,一定要考虑注册自定义的类,并且禁用对应引用的tracking(spark.Kryo.referenceTracking)</p>
<p>在写特殊的场景下,比如需要为流式应用保持的数据总量并不是很多,也许可以将数据以非序列化的方式进行持久化,从而减少序列化和反序列化的cpu开销,而且又不会有太昂贵的GC开销,那么你可以考虑通过显示的设置持久化级别,来禁止持久化时对数据进行序列化,这样就减少用于序列化和反序列化的cpu性能开销,并且不用承担太多的gc开销</p>
<h1 id="batch-interval"><a href="#batch-interval" class="headerlink" title="batch interval"></a>batch interval</h1><p>如果想让一个运行在集群上的spark streaming应用程序可以稳定,他就必须尽可能快的处理接收到的数据,换句话说,batch应该在生成之后,就尽可能的处理掉,对于一个应用来说,可以通过观察spark UI上的batch的处理时间来定,batch处理时间必须小于batch interval时间,不然上一个batch还没有处理成功,那么下一个batch就来了,这样会造成数据堆积</p>
<p>基于流式计算的本质,batch interval对于,在固定集群资源条件下,应用能保持的数据接收速率,会有巨大的影响,例如:在WordCount例子中,对于一个特定的数据接收速率,应用业务可以保证每2秒打印一次单词计数,而不是每500ms,因为batch interval 需要被设置的让与其的数据接收速率可以在生产环境中保持住</p>
<p>为你的应用计算正确的batch大小的比较好的方法,是在一个很保守的batch interval ,比如5-10s,以很慢的数据接收速率进行测试,要检查应用是否跟得上这个数据速率,可以检查每个batch的处理时间的延迟,如果处理时间与batch interval基本吻合,那么应用就是稳定的,否则,如果batch调度的延迟持续增加,那么就意味着无法跟得上这个速率,也就是不稳定的,因此,你要想有一个稳定的配置,可以尝试提升数据处理的速度,或者增加batch interval,记住,由于临时性的数据增长导致的暂时的延迟,可以合理的,只要延迟情况可以在短时间内恢复即可</p>
<h1 id="内存调优"><a href="#内存调优" class="headerlink" title="内存调优"></a>内存调优</h1><p>Transformation操作会决定你的内存的使用:<br>spark streaming应用需要的集群内UC你资源,是由使用的Transformation操作类型决定的,举例来说,如果想要使用一个窗口长度为10分钟的window操作,那么集群就必须有足够的内存来保存10分钟的数据,如果想要使用updateStateByKey来维护许多key的state,那么你的内存资源就必须足够大,返货来说,如果想要做一个简单的map-filter-sotre操作,那么需要使用的内存就很少</p>
<p>通常来说,通过Receiver接收到的数据,会使用StorageLevel.MEMORY_AND_DISK_SER_2持久化级别来进行存储,因此无法保存在内存中的数据会溢写到磁盘上,而溢写到磁盘上,是会降低应用的性能的,因此,通常是建议为应用提供他需要的足够的内存资源,建议在一个小规模的场景下测试内存的使用量,并进行评估</p>
<p>内存调优的另外一个方面是垃圾回收,对于流式应用来说,如果要获得低延迟的,肯定不想要有因为JVM垃圾回收导致的长时间延迟,有很多参数可以帮助降低内存使用和GC开销:<br>1.DStream的持久化级别:<br>输入数据和某些操作产生的中间RDD,默认持久化时都会序列化为字节,与非序列化的方式相比,这会降低内存和GC开销,使用Kryo序列化机制可以进一步减少内存使用和GC开销,进一步降低内存使用率,可以对数据进行压缩,由”spark.rdd.compress”参数控制(默认false)</p>
<p>2.清理旧数据:<br>默认情况下,所有输入数据和通过DStream Transformation操作生成的持久化的RDD,会自动被清理,spark streaming会决定何时清理这些数据,取决于Transformation操作类型,例如:你在使用窗口长度为10分钟的window操作,spark会保持10分钟以内的数据,时间过了以后会清理旧数据,但是在某些特殊场景下,比如spark sql和spark streaming整合使用时,在异步开启的线程中,使用spark streaming针对batch RDD进行执行查询,那么就㤇让spark 保持更长时间的数据,知道sparksql查询结束,可以使用:streamingContext.remember()方法来实现</p>
<p>3.CMS垃圾回收:<br>使用并行的mark-sweep垃圾回收机制,被推荐使用,用来保持GC开销,虽然并行的GC会降低吞吐量,但是还是建议使用它,来减少batch的处理时间(降低处理过程中的gc开销),如果要使用,那么要在driver端和Executor端都开启,在spark-submit中使用–driver-java-options设置,使用spark.executor.extra.javaOptions参数设置<br>XX:+UseConMarkSweepGC</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之实时wordcount程序开发/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之实时wordcount程序开发/" itemprop="url">
                  SparkStreaming之实时wordcount程序开发
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">// local后面必须跟一个方括号,里面填写一个数字,代表了用几个线程来执行我们的spark streaming程序</div><div class="line">val conf = new SparkConf()</div><div class="line">  .setAppName(&quot;Streaming&quot;)</div><div class="line">  .setMaster(&quot;local[2]&quot;)</div><div class="line">// 每收集多长时间的数据就划分为一个batch进行处理,这里设置为1秒:Seconds(1)</div><div class="line">val ssc = new StreamingContext(conf,Seconds(1))</div><div class="line"></div><div class="line">// 首先,创建输入DStream,代表了一个从数据源(kafka,socket)来的持续不断的实时数据流</div><div class="line">// 这里创建的数据源是socket:参数:监听的主机和端口</div><div class="line">val lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)</div><div class="line">// 返回的是一个DStream,表示每隔一秒会有一个RDD,其中封装了这一秒发送过来的数据</div><div class="line">// RDD的元素类型为String,即一行一行的文本</div><div class="line"></div><div class="line">// 开始对接收到的数据,对DStream执行算子操作</div><div class="line">// 在底层实际上会对DStream中的一个一个的RDD,执行我们应用在DStream上的算子</div><div class="line">// 产生的新的RDD会作为新DStream中的RDD</div><div class="line">val words = lines.flatMap(_.split(&quot; &quot;))</div><div class="line">val pairs = words.map((_,1))</div><div class="line">val wordCounts = pairs.reduceByKey(_ + _)</div><div class="line"></div><div class="line">// 可以看到spark streaming开发程序和spark core很像</div><div class="line">// 因为DStream是对Rdd的封装,那么DStream操作,就是对Rdd的操作</div><div class="line"></div><div class="line">// 休眠,打印(测试用)</div><div class="line">Thread.sleep(50000)</div><div class="line">wordCounts.print</div><div class="line"></div><div class="line">ssc.start()</div><div class="line">ssc.awaitTermination()</div><div class="line"></div><div class="line">/*总结:</div><div class="line">1.每秒钟发送到指定socket端口中的数据,都会被lines DStream接收到</div><div class="line">2.lines DStream会把每秒的数据,也就是一行一行的文本,诸如&quot;hello world&quot;, 封装成一个RDD</div><div class="line">3.然后对每秒钟中对应的RDD执行后续的一系列的算子操作</div><div class="line">4.最终就得到了每秒钟发送过来的单词统计</div><div class="line">5.可以将最后计算出的wordcount中的一个一个的RDD,写入外部的缓存,或者持久化DB</div><div class="line"> */</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之基本工作原理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之基本工作原理/" itemprop="url">
                  SparkStreaming之基本工作原理
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>接收实时输入数据流,然后将数据拆分成多个batch,比如每收集1s的数据封装为一个batch,然后将每个batch交给spark的计算引擎进行处理,最后会产生出一个结果数据流,其中的数据,也是由一个一个的batch所组成的</p>
<p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/sparkstreaming_yuanli.png" alt=""></p>
<p>DStream</p>
<p>Spark Streaming提供了一种高级的抽象,叫做Dstream(Discretized Stream 离散流),他代表了一个持续不断的数据流,DStream可以通过输入数据源来创建,比如:Kafka,Flume,Kinesis,也可以通过对其他DStream应用高阶函数来创建,比如:map,reduce,join,window</p>
<p>DStream的内部,其实是一系列持续不断产生的RDD,DStream中的每个RDD都包含了一个时间段内的数据</p>
<p>对DStream应用的算子,比如map,其实在底层会被翻译为对DStream中每个RDD的操作,比如对一个DStream执行一个map操作,会产生一个新的DStream,但是,在底层,其实其原理为,对输入DStream中每个时间段的RDD,都应用一遍map操作,然后生成新的RDD,即作为新的DStream中的那个时间段的一个RDD,底层的RDD的Transformation操作,其实,还是由spark core的计算引擎来实现的,spark Streaming对spark core进行了一层封装,隐藏了细节,然后对开发人员提供了方便易用的高层次的API</p>
<p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/DStream2.png" alt=""></p>
<p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/SparkStreaming之基本工作原理.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之介绍/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之介绍/" itemprop="url">
                  SparkStreaming之介绍
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>SparkStreaming其实就是一种spark提供的一种实时计算框架,他的底层组件或者概念,其实还是最核心的RDD,只不过,针对实时计算的特点,在RDD之上,进行了一层封装,叫做Dstream,就像spark sql针对数据查询应用提供了一种基于RDD之上的全新的概念叫DataFrame一样</p>
<p>spark Streaming是spark core API的一种扩展,他可以用于进行大规模,高吞吐,容错的实时数据流的处理,他支持从多种数据源中消费数据,比如:kafka,flume,Twitter,ZeroMQ,或者TCP Socket,并且能够使用类似高阶函数的复杂算法来进行数据处理,比如:map,reduce,join,和window,处理后的数据可以被保存到文件系统,数据库等存储中</p>
<p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/sparkstreaming_jianjie.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之与缓存与持久化机制/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之与缓存与持久化机制/" itemprop="url">
                  SparkStreaming之与缓存与持久化机制
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>与RDD类似,spark streaming也可以让开发人员手动控制,将数据流中的数据持久化到内存中,对DStream调用persist()方法,就可以让spark streaming自动将该数据流中的所有产生的RDD,都持久化到内存中</p>
<p>如果要对一个DStream多次执行操作,那么对DStream持久化是非常有用的,因为多次操作,可以共享使用内存中的一份缓存数据,对于基于窗口的操作,比如reduceByKeyAndWindow,以及基于状态的操作,比如updateStateByKey,默认就隐式开启了持久化的机制,即spark streaming默认就会将上述操作产生的数据,缓存到内存中,不需要开发人员手动调用persist()方法</p>
<p>对于通过网络接收数据的输入流,比如:socket,kafka,flume等,默认的持久化级别是将数据复制一份,以便于容错</p>
<p>与RDD不同的是,默认的持久化级别,统一都是要序列化的</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之与Storm的对比分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之与Storm的对比分析/" itemprop="url">
                  SparkStreaming之与Storm的对比分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>sparkStreaming与storm的对比</p>
<p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/sparkStreaming与storm的对比.png" alt=""></p>
<p>sparkStreaming与storm的优劣分析</p>
<p>事实上,spark streaming绝对谈不上比Storm优秀,这两个框架在实时计算领域中,都很优秀,只是擅长的细分场景并不相同</p>
<p>spark streaming仅仅在吞吐量上比storm要优秀,而吞吐量这一点,也是历来挺spark streaming的人着重强调的,但是问题是,并不是所有的实时计算场景下,都那么注重吞吐量,因此,通过吞吐量说spark streaming强于storm并不能说服人</p>
<p>事实上,storm在实时延迟度上,比spark streaming就好多了,前者是纯实时的,但是后者是准实时的,而且,storm的事务机制,健壮性,容错性,动态调整并行度等特性,都要比spark streaming更加优秀</p>
<p>spark streaming有一点是storm绝对比不上的,就是:它位于spark生态技术栈中,因此,spark streaming可以和spark core,spark sql无缝整合,也就意味着,我们可以对实时处理出来的中间数据,立即在程序中无缝进行延时批处理,交互式查询等操作,这个特点大大增强了spark streaming的优势和功能</p>
<p>spark streaming与storm的应用场景<br>对于storm来说:<br>1.建议那种需要纯实时,不能忍受1秒以上延时的场景下使用,比如实时金融系统,要求纯实时进行金融交易和分析<br>2.此外,如果对于实时计算的功能中,要求可靠的事务机制,即数据的处理完全精准,一条也不能少,一条也不能多,那么可以考虑storm<br>3.如果还需要针对高峰低峰时间段,动态调整实时计算程序的并行度,以最大限度利用集群资源(通常是小型公司,集群资源紧张的情况),也可以考虑storm<br>4.如果一个大数据应用系统,他就是纯粹的实时计算,不需要在中间执行sql交互式查询,复杂的Transformation算子等,那么用storm是比较好的选择</p>
<p>对于spark streaming来说:<br>1.如果对上述适用于storm的三点,一条都不满足的实时场景,即:不要求纯实时,不要求强大可靠的事务机制,不要求动态调整并行度,那么可以考虑使用spark streaming<br>2.考虑使用spark streaming最主要的一个因素,应该是针对整个项目进行宏观的考虑,可能还会牵扯到高延迟批处理,交互式查询等功能,那么就应该首先spark生态,用spark core开发离线批处理,用spark sql开发交互式查询,用spark streaming开发实时计算,三者可以无缝整合,给系统提供非常高的可扩展性</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之与Spark sql结合使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之与Spark sql结合使用/" itemprop="url">
                  SparkStreaming之与Spark sql结合使用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>spark Streaming 最强大的地方在于,可以与spark core, spark sql整合使用的,下面来看看,如何将DStream中的RDD与spark sql结合起来使用</p>
<p>案例:每隔10秒,统计最近60秒的,每个种类的每个商品的点击次数,然后统计出每个种类的top3热门商品</p>
<p>实现:<br>1.每隔10秒,统计最近60秒的,每个种类的每个商品的点击次数:用到的是reduceByKeyAndWindow<br>2.统计出每个种类的top3热门商品:用到的是DStream.foreachRDD然后对每次生成的窗口中的RDD进行sql查询,取top3</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line">val conf = new SparkConf()</div><div class="line">  .setAppName(&quot;Streaming&quot;)</div><div class="line">  .setMaster(&quot;local[2]&quot;)</div><div class="line"></div><div class="line">// 每收集多长时间的数据就划分为一个batch进行处理,这里设置为1秒:Seconds(1)</div><div class="line">val ssc = new StreamingContext(conf,Seconds(5))</div><div class="line"></div><div class="line">// 输入日志的格式:username product1 catatory</div><div class="line">// zhangsan iphone  mobile_phone</div><div class="line">val productClickLogsDStream = ssc.socketTextStream(&quot;spark1&quot;, 9999)</div><div class="line"></div><div class="line">// 要统计:每个种类的每个商品的点击次数,所以我们将数据格式转成:(category_product,1)</div><div class="line">// 然后使用window操作,对窗口中的数据进行reduceByKey</div><div class="line">// 从而统计出一个窗口中的每个种类的每个商品的点击次数</div><div class="line">val productClickLogsPairs = productClickLogsDStream.map&#123;</div><div class="line">  line=&gt;</div><div class="line">    val arr = line.split(&quot; &quot;)</div><div class="line">    (arr(2)+&quot;_&quot;+arr(1),1)</div><div class="line">&#125;</div><div class="line"></div><div class="line">// 计算60s内每个种类的每个商品的点击次数统计</div><div class="line">val categoryProductCountsDStream = productClickLogsPairs.reduceByKeyAndWindow((x:Int,y:Int)=&gt;x+y, Durations.seconds(60),Durations.seconds(10))</div><div class="line">//</div><div class="line">val categoryProductCountRowRdd = categoryProductCountsDStream.foreachRDD&#123;</div><div class="line">  categoryProductCountsRdd=&gt;</div><div class="line">    val rowRdd = categoryProductCountsRdd.map&#123;</div><div class="line">      categoryProductCount=&gt;</div><div class="line">        val (category,product) = categoryProductCount._1.split(&quot;_&quot;).toVector</div><div class="line">        val count = categoryProductCount._2</div><div class="line">        Row(category,product,count)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    val structType = StructType(Array(</div><div class="line">      StructField(&quot;category&quot;, StringType, true),</div><div class="line">      StructField(&quot;product&quot;, StringType, true),</div><div class="line">      StructField(&quot;click_count&quot;, IntegerType, true)</div><div class="line">    ))</div><div class="line">    val sqlContext = new HiveContext(rowRdd.sparkContext)</div><div class="line">    val categoryProductCountsDF = sqlContext.createDataFrame(rowRdd,structType)</div><div class="line">    categoryProductCountsDF.registerTempTable(&quot;product_click_log&quot;)</div><div class="line"></div><div class="line">    // 使用spark sql执行top3热门商品的统计</div><div class="line">    val top3ProductDF = sqlContext.sql(&quot;&quot; +</div><div class="line">      &quot;select category, product, click_count&quot; +</div><div class="line">      &quot;from (&quot; +</div><div class="line">      &quot;   select &quot; +</div><div class="line">      &quot;       category,&quot; +</div><div class="line">      &quot;       product,&quot; +</div><div class="line">      &quot;       click_count,&quot; +</div><div class="line">      &quot;       row_number() over (partition by category order by click_count desc) rank&quot; +</div><div class="line">      &quot;    from product_click_log&quot; +</div><div class="line">      &quot;) tmp&quot; +</div><div class="line">      &quot;where rank &lt;= 3&quot;)</div><div class="line"></div><div class="line">    // 将数据保存到redis或者db中,然后在web中对数据进行展示</div><div class="line">    // 但是这里只是测试,所以用show</div><div class="line">    top3ProductDF.show</div><div class="line">&#125;</div><div class="line"></div><div class="line">ssc.start()</div><div class="line">ssc.awaitTermination()</div><div class="line">ssc.stop()</div></pre></td></tr></table></figure>
<p>spark-submit<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">/usr/local/spark/bin/spark-submit \</div><div class="line">--class cn.xxx.Top3HotProduct</div><div class="line">--num-executor 3 \</div><div class="line">--driver-memory 100m \</div><div class="line">--execuotr-memory 100m \</div><div class="line">--executor-cores 3 \</div><div class="line">--files /usr/local/hive/conf/hive-site.xml</div><div class="line">--driver-class-path /usr/local/hive/lib/mysql-connector-java-5.1.17.jar \</div><div class="line">/user/xx/spark-study-test.jar \</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之window滑动窗口/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之window滑动窗口/" itemprop="url">
                  SparkStreaming之window滑动窗口
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>spark streaming提供了滑动窗口操作的支持,从而让我们可以对一个滑动窗口内的数据执行计算操作,每次掉落在窗口内的RDD的数据,会被聚合起来执行计算操作,然后生成的RDD,会作为window DStream的一个RDD,比如下图中,就是对每三秒钟的数据执行一次滑动窗口计算,这3秒内的3个RDD会被聚合起来进行处理,然后过了2秒钟,又会对最近3秒内的数据执行滑动窗口计算,所以每个滑动窗口操作,都必须指定2个参数,窗口长度以及滑动间隔,而且这两个参数值都必须是batch间隔的整数倍</p>
<p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/window.png" alt=""></p>
<p>window滑动窗口的操作</p>
<table>
<thead>
<tr>
<th style="text-align:left">Transformation</th>
<th style="text-align:left">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">window</td>
<td style="text-align:left">对每个滑动窗口的数据执行自定义的计算</td>
</tr>
<tr>
<td style="text-align:left">countByWindow</td>
<td style="text-align:left">对每个滑动窗口的数据执行count操作</td>
</tr>
<tr>
<td style="text-align:left">reduceByWindow</td>
<td style="text-align:left">对每个滑动窗口的数据执行reduceByKey操作</td>
</tr>
<tr>
<td style="text-align:left">reduceByKeyAndWindow</td>
<td style="text-align:left">对每个滑动窗口的数据执行reduceByKey操作</td>
</tr>
<tr>
<td style="text-align:left">countByValueAndWindow</td>
<td style="text-align:left">对每个滑动窗口的数据执行countByValue操作</td>
</tr>
</tbody>
</table>
<p>案例:热点搜索词滑动统计,每隔5秒钟,统计最近10秒钟的搜索词的搜索频次,并打印出来排名最靠前的3个搜索词以及出现次数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">val conf = new SparkConf()</div><div class="line">  .setAppName(&quot;Streaming&quot;)</div><div class="line">  .setMaster(&quot;local[2]&quot;)</div><div class="line"></div><div class="line">// 每收集多长时间的数据就划分为一个batch进行处理,这里设置为1秒:Seconds(1)</div><div class="line">val ssc = new StreamingContext(conf,Seconds(5))</div><div class="line"></div><div class="line">// 搜素日志的格式: username searchWord</div><div class="line">val searchLog = ssc.socketTextStream(&quot;spark1&quot;, 9999)</div><div class="line">// (searchWord,1)</div><div class="line">val searchWordPairDStream = searchLog.map(_.split(&quot; &quot;)(2)).map((_,1))</div><div class="line"></div><div class="line">/*</div><div class="line">第一个参数是:reduceByKey中的需要指定的函数</div><div class="line">第二个参数是:窗口长度,这里是60秒</div><div class="line">第三个参数:滑动间隔,这是是10秒</div><div class="line">也就是说:每隔10秒钟,将最近60秒的数据,作为一个窗口,</div><div class="line">进行内部的RDD的聚合,统一成一个RDD,然后进行后续计算</div><div class="line"></div><div class="line">每隔10秒钟,就会滑动一下,会将之前60秒的RDD(因为一个batch的间隔是5秒,</div><div class="line">所以之前60秒就有12个RDD)给聚合起来统一执行reduceByKey操作,</div><div class="line">所以这里的reduceByKeyAndWindow是针对每隔窗口执行计算的,而不是针对某个DStream中的RDD</div><div class="line"> */</div><div class="line">val searchWordCountsDStream = searchWordPairDStream.reduceByKeyAndWindow((x:Int,y:Int)=&gt;x+y,Durations.seconds(60),Durations.seconds(10))</div><div class="line">/*</div><div class="line"> @param reduceFunc associative and commutative reduce function</div><div class="line"> @param windowDuration width of the window; must be a multiple of this DStream&apos;s batching interval(必须是batch的整数倍)</div><div class="line"> @param slideDuration  sliding interval of the window</div><div class="line"> */</div><div class="line"></div><div class="line">// 执行transform,因为一个窗口就是一个60秒钟的数据,会变成一个RDD,</div><div class="line">// 然后对这一个RDD根据每个搜索词出现的频率进行排序,</div><div class="line">// 然后获取排名前3的热点搜索词</div><div class="line">val finalDStream = searchWordCountsDStream.transform&#123;</div><div class="line">  searchWordCountsRdd=&gt;</div><div class="line">    // 执行搜索词和频率的反转,格式为:(count, searchWord)</div><div class="line">    val searchCountsWordRdd = searchWordCountsRdd.map(t=&gt;(t._2, t._1))</div><div class="line">    val searchCountsWordSortedRdd = searchCountsWordRdd.sortByKey(false)</div><div class="line">    // 格式为:(searchWord, count)</div><div class="line">    val searchWordCountsSortedRdd = searchCountsWordSortedRdd.map(t=&gt;(t._2, t._1))</div><div class="line">    // 然后take(),获取排名前3的特点搜索词</div><div class="line">    val top3SearchWordCounts = searchWordCountsSortedRdd.take(3)</div><div class="line"></div><div class="line">    top3SearchWordCounts.foreach(println)</div><div class="line"></div><div class="line">    null</div><div class="line">&#125;</div><div class="line"></div><div class="line">// 触发</div><div class="line">finalDStream.print</div><div class="line"></div><div class="line">ssc.start()</div><div class="line">ssc.awaitTermination()</div><div class="line">ssc.stop()</div><div class="line">/*</div><div class="line">其实window函数就是对一个时间段中的数据进行统计,比如:看过去60秒钟内的热点搜索词</div><div class="line"> */</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之updateStateByKey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之updateStateByKey/" itemprop="url">
                  SparkStreaming之updateStateByKey和WordCount全局统计
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>updateStateByKey操作,可以让我们为每个key维护一份state,并持续不断的更新该state<br>1.首先,定义个state,可以是任意的数据类型<br>2.其次,要定义state更新函数—指定一个函数如何使用之前的state和新值来更新state</p>
<p>对于每个batch,spark都会为每个之前已经存在的key去应用一次state更新函数,无论这个key在batch中是否有新的数据,如果state更新函数返回none,那么key对应的state就会被删除</p>
<p>当然,对于每个新初出现的key,也会执行state更新操作</p>
<p>注意,updateStateByKey操作,要求必须开启checkpoint机制</p>
<p>案例:基于缓存的实时WordCount程序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">val conf = new SparkConf()</div><div class="line">  .setAppName(&quot;Streaming&quot;)</div><div class="line">  .setMaster(&quot;local[2]&quot;)</div><div class="line"></div><div class="line">// 每收集多长时间的数据就划分为一个batch进行处理,这里设置为1秒:Seconds(1)</div><div class="line">val ssc = new StreamingContext(conf,Seconds(1))</div><div class="line"></div><div class="line">// 如果要使用updateStateByKey算子,就必须设置一个checkpoint目录,</div><div class="line">// 这样便于在内存数据丢失的时候,可以从checkpoint中恢复数据</div><div class="line">ssc.checkpoint(&quot;hdfs://spark1:9000/wordcount_checkpoint&quot;)</div><div class="line"></div><div class="line">val updateFunc = (iter: Iterator[(String, Seq[Int], Option[Int])]) =&gt; &#123;</div><div class="line">  //iter.flatMap(it=&gt;Some(it._2.sum + it._3.getOrElse(0)).map(x=&gt;(it._1,x)))</div><div class="line">  iter.flatMap &#123; case (x, y, z) =&gt; Some(y.sum + z.getOrElse(0)).map(i =&gt; (x, i)) &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">val lines = ssc.socketTextStream(&quot;localhost&quot;,9999)</div><div class="line">val pairs = lines.flatMap(_.split(&quot; &quot;)).map((_,1))</div><div class="line">// 在之前的WordCount中,是直接使用pairs.reduceByKey</div><div class="line">// 得到的是每个时间段的batch对应的RDD,这样计算出来的是那个时间段的单词计数</div><div class="line">// 但是如果我们想要统计每个单词的全局的计数呢?</div><div class="line">// 就是说:统计出来从程序启动开始,到现在为止,统计一个单词出现的次数,那么之前的方式就不好实现了</div><div class="line">// 就必须基于redis缓存,或者mysql来实现累加</div><div class="line">// 但是我们的updateStateByKey就可以维护一份每个单词的全局的统计次数</div><div class="line"></div><div class="line">/*实际上,对于每个单词,每次batch的时候,都会调用这个函数</div><div class="line">第一个参数values:相当于这个batch中,这个key的新的值,可能有多个</div><div class="line">比如说:(hello,1) (hello,1),那么传入的是(1,1)</div><div class="line">第二个参数state:就是指的是这个key之前的状态,其中的泛型的类型是自己指定的</div><div class="line"> */</div><div class="line">val func2 = (values:Seq[Int], state:Option[Int])=&gt;&#123;</div><div class="line">  val newValue = state.getOrElse(0)//之前的状态不存在返回0</div><div class="line">  Option(newValue + values.sum)//将本次新出现的值求和,然后再和state的值相加,就是这个key目前的全局统计</div><div class="line">&#125;</div><div class="line">val wordCounts = pairs.updateStateByKey(func2)//其实内部就是调用的是下面的一种方式,只不过使用func2的方法更加的简洁</div><div class="line">//val wordCounts = pairs.updateStateByKey(updateFunc,new HashPartitioner(ssc.sparkContext.defaultParallelism), true)</div><div class="line">/*</div><div class="line">默认的情况:</div><div class="line">new HashPartitioner(ssc.sparkContext.defaultParallelism) 是指定分区函数,默认就是使用的是HashPartitioner</div><div class="line">true:Whether to remember the partitioner object in the generated RDDs.</div><div class="line"> */</div><div class="line">wordCounts.print</div><div class="line"></div><div class="line">ssc.start()</div><div class="line">ssc.awaitTermination()</div><div class="line">ssc.stop()</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/41/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/41/">41</a><span class="page-number current">42</span><a class="page-number" href="/page/43/">43</a><span class="space">&hellip;</span><a class="page-number" href="/page/56/">56</a><a class="extend next" rel="next" href="/page/43/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/header.jpg"
               alt="Mr. Chen" />
          <p class="site-author-name" itemprop="name">Mr. Chen</p>
           
              <p class="site-description motion-element" itemprop="description">一个技术渣的自说自话</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">555</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">28</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">36</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mr. Chen</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  





  

  

  

  

  

</body>
</html>
