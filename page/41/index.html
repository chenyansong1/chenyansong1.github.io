<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="一个技术渣的自说自话">
<meta property="og:type" content="website">
<meta property="og:title" content="Chen's Blog">
<meta property="og:url" content="http://yoursite.com/page/41/index.html">
<meta property="og:site_name" content="Chen's Blog">
<meta property="og:description" content="一个技术渣的自说自话">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chen's Blog">
<meta name="twitter:description" content="一个技术渣的自说自话">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"right","display":"always","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/41/"/>





  <title> Chen's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-right 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chen's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">一个技术渣的自说自话</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/spark内核源码九之shuffle原理剖析与源码分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/spark内核源码九之shuffle原理剖析与源码分析/" itemprop="url">
                  spark内核源码九之shuffle原理剖析与源码分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="在spark中-什么情况下会发生shuffle"><a href="#在spark中-什么情况下会发生shuffle" class="headerlink" title="在spark中,什么情况下会发生shuffle?"></a>在spark中,什么情况下会发生shuffle?</h1><p>reduceByKey,groupByKey,sortByKey,countByKey,join,cogroup</p>
<h1 id="默认的shuffle操作的原理-vs-优化后的shuffle操作的原理"><a href="#默认的shuffle操作的原理-vs-优化后的shuffle操作的原理" class="headerlink" title="默认的shuffle操作的原理 vs 优化后的shuffle操作的原理"></a>默认的shuffle操作的原理 vs 优化后的shuffle操作的原理</h1><p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/spark内核源码九之shuffle原理剖析与源码分析.png" alt=""></p>
<h1 id="shuffle相关源码"><a href="#shuffle相关源码" class="headerlink" title="shuffle相关源码"></a>shuffle相关源码</h1><p>shuffle的写源码:</p>
<p>ShuffleMapTask.runTask()是入口,writer默认是HashShuffleWriter</p>
<p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/shuffle的IO写.png" alt=""></p>
<p>shuffle的读源码:</p>
<p>可以从一个rdd开始入手,如ShuffledRDD的compute方法</p>
<p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/shuffle的读.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/spark内核源码三之Worker原理解析及源码分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/spark内核源码三之Worker原理解析及源码分析/" itemprop="url">
                  spark内核源码三之Worker原理解析及源码分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/Worker原理解析及源码分析.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/spark内核源码七之TaskScheduler原理剖析与源码分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/spark内核源码七之TaskScheduler原理剖析与源码分析/" itemprop="url">
                  spark内核源码七之TaskScheduler原理剖析与源码分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在<strong>spark内核源码六之DAGScheduler原理剖析与源码分析</strong>一文中,最后dagScheduler将stage分成taskSet,使用taskScheduler.submitTasks去提交<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">taskScheduler.submitTasks(new TaskSet())</div></pre></td></tr></table></figure></p>
<p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/spark内核源码七之TaskScheduler原理剖析与源码分析.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/spark内核源码一之SparkContext原理解析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/spark内核源码一之SparkContext原理解析/" itemprop="url">
                  spark内核源码一之SparkContext原理解析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/SparkContext的初始化.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/spark_shell/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/spark_shell/" itemprop="url">
                  spark shell
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">spark-shell</div></pre></td></tr></table></figure></p>
<p>使用一个shell脚本去提交程序</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">[root@hdp-node-01 install]# cat wordcount.sh </div><div class="line">/install/spark-1.6.1-bin-hadoop2.6/bin/spark-submit \</div><div class="line">--class cn.... \</div><div class="line">--num-executors 3 \</div><div class="line">--driver-memory 100m \</div><div class="line">--executor-memory 100m \</div><div class="line">--executor-cores 3 \</div><div class="line">xxxx.jar</div><div class="line"></div><div class="line"></div><div class="line">####上面的代码是本地模式运行,但是如果要提交到集群上需要加上--master</div><div class="line">/install/spark-1.6.1-bin-hadoop2.6/bin/spark-submit \</div><div class="line">--class cn.... \</div><div class="line">--master spark://node1:7077 \</div><div class="line">--num-executors 3 \</div><div class="line">--driver-memory 100m \</div><div class="line">--executor-memory 100m \</div><div class="line">--executor-cores 3 \</div><div class="line">xxxx.jar</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之部署,审计,监控应用程序/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之部署,审计,监控应用程序/" itemprop="url">
                  SparkStreaming之部署,升级,监控应用程序
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/bushu.png" alt=""><br><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/wal.png" alt=""><br><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/bushu2.png" alt=""></p>
<h1 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h1><p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/shengji.png" alt=""></p>
<h1 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h1><p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/jiankong.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之输入DStream的Transformation操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之输入DStream的Transformation操作/" itemprop="url">
                  SparkStreaming之输入DStream的Transformation操作
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>map        对传入的每个元素,返回一个新的元素<br>flatMap    对传入的每个元素,返回一个或多个元素<br>filter    对传入的元素返回true或false,返回的false的元素被过滤掉<br>union    将两个DStream进行合并<br>count    返回元素的个数<br>reduce    对所有的values进行聚合<br>countByValue    对元素按照值进行分组,对每个组进行计数,最后返回<k,v>格式<br>reduceByKey        对key对应的values进行聚合<br>cogroup            对两个DStream进行连接操作,一个key连接起来的两个RDD的数据,都会以Iterable<v>的形式,<key,tuple<iterable1,iterable2>&gt;<br>join    对两个DStream进行join操作,每个连接起来的pair,作为新DStream的RDD的一个元素<br>transform    对数据进行转换操作<br>updateStateByKey    为每个key维护一份state,并进行更新<br>window        对滑动窗口数据执行操作</key,tuple<iterable1,iterable2></v></k,v></p>
<p>RDD1=(1,1) (1,2) (1,3)<br>RDD2=(1,4) (2,1) (2,2)</p>
<p>RDD1 cogroup RDD2<br>cogroup—&gt;(1,((1,2,3),(4))</p>
<p>RDD1 join RDD2<br>join——&gt;(1,(1,4))  (1,(2,4))      (1,(3,4)</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之输入DStream和Receiver/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之输入DStream和Receiver/" itemprop="url">
                  SparkStreaming之输入DStream和Receiver
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>输入DStream代表了来自数据源的输入数据流,在之前的WordCount例子中,lines就是一个输入DStream(SocketInputDStream),代表了从socket服务接收到的数据流,除了文件数据流之外,所有的输入DStream都会绑定一个Receiver对象,该对象是一个关键的组件,用来从数据源接收数据,并将其存储在spark的内存中,以供后续处理</p>
<p>spark Streaming提供了两种内置的数据源的支持<br>1.基础数据源:StreamingContext API(如:StreamingContext.socketTextStream()方法)中直接提供了对这些数据源的支持,比如:文件,socket,Akka Actor等,<br>2.高级数据源:诸如Kafka,flume,Kinesis,Twitter等书卷,通过第三方工具类提供支持,这些数据源的使用,需要引用其依赖<br>3.自定义数据源:我们可以自己定义数据源,来决定如何接受和存储数据</p>
<p>输入DStream和Receiver详解</p>
<p>要注意的是,如果你想要在实时计算应用中并行接收多条数据流,可以创建多个输入DStream,这样就会创建多个Receiver,从而并行的接收多个数据流,但是要注意的是,一个spark Streaming Application的Executor是一个长时间运行的任务,因此,他会独占分配给spark streaming Application的cpu core,从而只要spark streaming运行起来以后,这个节点上的cpu core,就没法给其他应用使用了</p>
<p>使用本地模式,运行程序时,绝对不能使用local或者是local[1],因为那样的话,只会给执行输入DStream的executor分配一个线程,而spark streaming底层的原理是,至少要有两条线程,一个线程用来分配给Receiver接收数据,一条线程用来处理接收到的数据,因此必须使用local[n],n&gt;=2的模式</p>
<p>如果不设置Master,也就是直接将spark streaming应用提交到集群上运行,那么首先,必须要求集群节点上,有&gt;1个cpu core,其次给spark streaming的每个executor分配的core,必须&gt;1,这样,才能保证分配到executor上运行的的输入DStream,两条线程并行,一条运行Receiver,接收数据,一条处理数据,否则的话,只会接收数据,不会处理数据</p>
<p>因此,在实际工作中,都要给每个executor的cpu core设置超过1个即可</p>
<p><img src="http://ols7leonh.bkt.clouddn.com//assert/img/bigdata/spark从入门到精通_笔记/Receiver.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之输入DStream之基础数据源/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之输入DStream之基础数据源/" itemprop="url">
                  SparkStreaming之输入DStream之基础数据源
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>基础数据源<br>1.socket:StreamingContext.socketTextStream()</p>
<p>2.HDFS文件<br>StreamingContext.fileStream()<br>基于HDFS的文件实时计算,其实就是监控一个HDFS目录,只要其中有新文件出现,就实时处理,相当于处理实时的文件流<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def fileStream[</div><div class="line">  K: ClassTag,</div><div class="line">  V: ClassTag,</div><div class="line">  F &lt;: NewInputFormat[K, V]: ClassTag</div><div class="line">] (directory: String): InputDStream[(K, V)]</div></pre></td></tr></table></figure></p>
<p>spark Streaming会监视指定的HDFS目录,并且处理出现在目录中的文件,要注意的是:<br>1.所有放入HDFS目录中的文件,都必须有相同的格式,<br>2.必须使用移动或者重命名的方式<br>3.将文件移入目录,一旦处理之后,文件的内容即使改变了,也不会再处理了<br>4.基于HDFS文件的数据源是没有Receiver的,因此不会占用一个cpu core</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">// local后面必须跟一个方括号,里面填写一个数字,代表了用几个线程来执行我们的spark streaming程序</div><div class="line">val conf = new SparkConf()</div><div class="line">  .setAppName(&quot;Streaming&quot;)</div><div class="line">  .setMaster(&quot;local[2]&quot;)</div><div class="line"></div><div class="line">// 每收集多长时间的数据就划分为一个batch进行处理,这里设置为1秒:Seconds(1)</div><div class="line">val ssc = new StreamingContext(conf,Seconds(1))</div><div class="line"></div><div class="line">// 针对HDFS目录创建DStream</div><div class="line">val lines = ssc.textFileStream(&quot;hdfs:spark1:9000/wordcount_dir&quot;)</div><div class="line">/* 其实在textFileStream底层是调用了fileStream</div><div class="line">  def textFileStream(directory: String): DStream[String] = withNamedScope(&quot;text file stream&quot;) &#123;</div><div class="line">    fileStream[LongWritable, Text, TextInputFormat](directory).map(_._2.toString)</div><div class="line">  &#125;</div><div class="line"> */</div><div class="line"></div><div class="line">// 执行WordCount逻辑</div><div class="line">val words = lines.flatMap(_.split(&quot; &quot;))</div><div class="line">val pairs = words.map((_,1))</div><div class="line">val wordcount = pairs.reduceByKey(_ + _)</div><div class="line"></div><div class="line">// 打印测试</div><div class="line">wordcount.print</div><div class="line"></div><div class="line">ssc.start()</div><div class="line">ssc.awaitTermination()</div><div class="line">ssc.stop()</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之输入DStream之Kafka基础数据源/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr. Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/16/bigdata/spark从入门到精通_笔记/SparkStreaming之输入DStream之Kafka基础数据源/" itemprop="url">
                  SparkStreaming之输入DStream之Kafka基础数据源
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-16T12:47:25+08:00">
                2017-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="基于Receiver的方式"><a href="#基于Receiver的方式" class="headerlink" title="基于Receiver的方式"></a>基于Receiver的方式</h1><p>这种方式使用Receiver来获取数据,Receiver是使用Kafka的高层次ConsumerAPI来实现的,receive从kafka中获取的数据都是存储在spark executor的内存中的,然后spark Streaming启动额job会去处理那些数据</p>
<p>然而,在默认的配置下,这种方式可能会因为底层的失败而丢失数据,如果要启用高可靠机制,让数据零丢失,就必须启用spark streaming 的预写日志机制(Write Ahead Log,WAL),该机制会tongue的将接收到的kafka数据写入分布式文件系统(比如HDFS)山的预写日志中,所以即使底层节点出现了失败,也可以使用预写日志中的数据进行恢复</p>
<p>前提:<br>1.maven添加依赖<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spark-streaming-kafka_2.11&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;1.6.3&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>
<p>2.使用第三方工具类创建输入DStream<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">KafkaUtils.createStream(StreamingContext,[ZK quorum], [consumer group id], [per-topic number of kakfa partitions to consume])</div></pre></td></tr></table></figure></p>
<p>注意事项:<br>1.kafka的topic的partition,与spark中的RDD的partition是没有关系的,所以在KafkaUtils.createStream()中,提高partition的数量,只会增加一个Receiver中读取partition的线程的数量,不会增加spark处理数据的并行度<br>2.可以创建多个kafka输入DStream,使用不同的consumer group和topic,来通过多个receiver并行接收数据<br>3.如果基于容错的文件系统,比如HDFS,启用了预写日志机制,接收到的数据都会被复制一份到预写日志中,因此在KafkaUtils.createStream()中,设置的持久化级别是:StorageLevel.MEMORY_AND_DISK_SER_2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">//创建topic</div><div class="line">bin/kafka-topic.sh --zookeeper zk01:2181,zk02:2181,zk03:2181 --topic WordCount --replication-factor 1 --partitions 1 --create</div><div class="line"></div><div class="line"></div><div class="line">//创建consumer生产者</div><div class="line">bin/kafka-console-producer.sh --broker-list 192.168.1.107:9092,192.168.1.108:9092,192.168.1.109:9092, --topic WordCount</div></pre></td></tr></table></figure>
<p>实例代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">// local后面必须跟一个方括号,里面填写一个数字,代表了用几个线程来执行我们的spark streaming程序</div><div class="line">val conf = new SparkConf()</div><div class="line">  .setAppName(&quot;Streaming&quot;)</div><div class="line">  .setMaster(&quot;local[2]&quot;)</div><div class="line"></div><div class="line">// 每收集多长时间的数据就划分为一个batch进行处理,这里设置为1秒:Seconds(1)</div><div class="line">val ssc = new StreamingContext(conf,Seconds(1))</div><div class="line"></div><div class="line">// 创建针对Kafka的输入流</div><div class="line">val zk = &quot;192.168.0.107:2181,192.168.0.108:2181,192.168.0.109:2181&quot;</div><div class="line">val  topicThreadMap = Map(</div><div class="line">  &quot;WordCount&quot;-&gt;1</div><div class="line">)</div><div class="line"></div><div class="line">// zk是zookeeper的节点地址</div><div class="line">// DefalutConsumerGroup是kafka的groupId</div><div class="line">// topicThreadMap是指定去消费哪个topic</div><div class="line">//Map of (topic_name -&gt; numPartitions) to consume. Each partition is consumed in its own thread</div><div class="line">// topic名字-&gt;分区数量,每个分区将会启动一个Receiver线程去消费(而一个Receiver需要一个cpu core)</div><div class="line">val lines = KafkaUtils.createStream(ssc,zk,&quot;DefalutConsumerGroup&quot;,topicThreadMap)</div><div class="line"></div><div class="line">// 这里需要注意的是lines中是Tuple(index,line)这样的数据,所以_._2就是一行的的数据</div><div class="line">val words = lines.flatMap(_._2.split(&quot; &quot;))</div><div class="line">val pairs = words.map((_,1))</div><div class="line">val wordcount = pairs.reduceByKey(_ + _)</div><div class="line"></div><div class="line">// 打印测试</div><div class="line">wordcount.print</div><div class="line"></div><div class="line"></div><div class="line">ssc.start()</div><div class="line">ssc.awaitTermination()</div><div class="line">ssc.stop()</div></pre></td></tr></table></figure>
<h1 id="基于Direct的方式"><a href="#基于Direct的方式" class="headerlink" title="基于Direct的方式"></a>基于Direct的方式</h1><p>这种是不基于Receiver的直接方式,是在spark1.3中引入,从而能够确保更加健壮的机制,替代掉使用Receiver来接收数据后,这种方式会周期性(就是我们指定的batch的时间)的查询Kafka,来获取每个topic+partition的最新的offset,从而定义每个batch的offset的范围(而每个batch会形成一个Rdd),当处理数据的job启动时,就会使用kafka的简单consumer API来获取kafka指定offset范围的数据,这就得到了这个Rdd的数据</p>
<p>这种方式有如下的优点:<br>1.简化并行读取,如果要有多个partition,不需要创建多个输入DStream然后对他们进行union操作,spark会创建跟kafka partition一样多的Rdd partition,并且会并行从kafka中读取数据,所在kafka partition和RDD partition之间,有一个一对一的映射关系<br>2.高性能:如果要保证零数据丢失,在语句Receiver的方式中,需要开启WAL机制,这种方式其实效率低下,因为数据实际上被复制了两份,kafka自己本身就有高可靠的机制,会对数据复制一份,而这里又会复制一份到WAL中,而基于direct的方式,不依赖Receiver,不需要开启WAL机制,只要kafka中作了数的复制,那么就可以通过kafka的副本进行恢复<br>3.一次仅且一次的事务机制<br>基于Receiver的方式,是使用kafka的高阶API来在zookeeper中保存消费过的offset,这是消费kafka数据的传统的方式,这种方式配合着WAL机制可以保证数据零丢失的高可靠性,但是却无法保证数据被处理一次且仅一次,可能会处理两次,因为spark和zookeeper之间可能是不同步的</p>
<p>基于direct的方式,使用kafka的简单API,spark streaming自己会负责追踪消费的offset并保存在checkpoint中,spark自己一定是同步的,因此可以保证数据是消费一次且仅消费一次</p>
<p>createDirectStream()方法参数说明</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">   *</div><div class="line">   * @param ssc StreamingContext object	这里是传入的一个StreamingContext</div><div class="line">   * @param kafkaParams Kafka &lt;a href=&quot;http://kafka.apache.org/documentation.html#configuration&quot;&gt;</div><div class="line">   *   configuration parameters&lt;/a&gt;. Requires &quot;metadata.broker.list&quot; or &quot;bootstrap.servers&quot; 必须要指定:&quot;metadata.broker.list&quot; or &quot;bootstrap.servers&quot;中的一个</div><div class="line">   *   to be set with Kafka broker(s) (NOT zookeeper servers), specified in</div><div class="line">   *   host1:port1,host2:port2 form.	//指定的格式</div><div class="line">   *   If not starting from a checkpoint, &quot;auto.offset.reset&quot; may be set to &quot;largest&quot; or &quot;smallest&quot;	//如果没有初始化的offset,那么从哪里开始消费(largest从头开始,smallest:从最近开始消费)</div><div class="line">   *   to determine where the stream starts (defaults to &quot;largest&quot;)</div><div class="line">   *   如果开始消费的数据不是从checkpoint中开始的,那么使用&quot;auto.offset.reset&quot; 参数设置成&quot;largest&quot; or &quot;smallest&quot;来决定从Stream流的哪里开始消费数据</div><div class="line">   * @param topics Names of the topics to consume	topic名称</div><div class="line">   * @tparam K type of Kafka message key	消息key的类型</div><div class="line">   * @tparam V type of Kafka message value	消息value的类型</div><div class="line">   * @tparam KD type of Kafka message key decoder	key的编码格式</div><div class="line">   * @tparam VD type of Kafka message value decoder	value的编码格式</div><div class="line">   * @return DStream of (Kafka message key, Kafka message value)</div><div class="line">   */</div><div class="line">  def createDirectStream[</div><div class="line">    K: ClassTag,</div><div class="line">    V: ClassTag,</div><div class="line">    KD &lt;: Decoder[K]: ClassTag,</div><div class="line">    VD &lt;: Decoder[V]: ClassTag] (</div><div class="line">      ssc: StreamingContext,</div><div class="line">      kafkaParams: Map[String, String],</div><div class="line">      topics: Set[String]</div><div class="line">  ): InputDStream[(K, V)]</div><div class="line"></div><div class="line"></div><div class="line">=========================================</div><div class="line">在kafka中对auto.offset.reset参数的解释是:</div><div class="line"></div><div class="line">What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server (e.g. because that data has been deleted):</div><div class="line">当没有初始化的offset的时候,此时该从哪里读取数据</div><div class="line"></div><div class="line">earliest: automatically reset the offset to the earliest offset	设置offset为最开始的处,即从头开始消费</div><div class="line">latest: automatically reset the offset to the latest offset	从设置offset为最近的offset</div><div class="line">none: throw exception to the consumer if no previous offset is found for the consumer&apos;s group</div><div class="line">anything else: throw exception to the consumer.</div></pre></td></tr></table></figure>
<p>实例代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">val conf = new SparkConf()</div><div class="line">  .setAppName(&quot;Streaming&quot;)</div><div class="line">  .setMaster(&quot;local[2]&quot;)</div><div class="line"></div><div class="line">// 每收集多长时间的数据就划分为一个batch进行处理,这里设置为1秒:Seconds(1)</div><div class="line">val ssc = new StreamingContext(conf,Seconds(1))</div><div class="line"></div><div class="line">// 创建针对Kafka的输入流</div><div class="line">val zk = &quot;192.168.0.107:2181,192.168.0.108:2181,192.168.0.109:2181&quot;</div><div class="line">val  kafkaParams = Map(</div><div class="line">  // kafka的broker-list</div><div class="line">  &quot;meta.broker.list&quot;-&gt;&quot;192.168.1.107:9092,192.168.1.108:9092,192.168.1.109:9092&quot;,</div><div class="line">)</div><div class="line"></div><div class="line">val topics = Set(</div><div class="line">  &quot;WordCount&quot;</div><div class="line">)</div><div class="line"></div><div class="line">val lines = KafkaUtils.createDirectStream[String, String, StringDecoder, StringDecoder](ssc,kafkaParams,topics)</div><div class="line">val words = lines.flatMap(_._2.split(&quot; &quot;))</div><div class="line">val pairs = words.map((_,1))</div><div class="line">val wordcount = pairs.reduceByKey(_ + _)</div><div class="line"></div><div class="line">// 打印测试</div><div class="line">wordcount.print</div><div class="line"></div><div class="line"></div><div class="line">ssc.start()</div><div class="line">ssc.awaitTermination()</div><div class="line">ssc.stop()</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/40/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/40/">40</a><span class="page-number current">41</span><a class="page-number" href="/page/42/">42</a><span class="space">&hellip;</span><a class="page-number" href="/page/56/">56</a><a class="extend next" rel="next" href="/page/42/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/header.jpg"
               alt="Mr. Chen" />
          <p class="site-author-name" itemprop="name">Mr. Chen</p>
           
              <p class="site-description motion-element" itemprop="description">一个技术渣的自说自话</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">555</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">28</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">36</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mr. Chen</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  





  

  

  

  

  

</body>
</html>
